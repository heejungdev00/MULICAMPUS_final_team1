{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","mount_file_id":"1_tMQdY4IsN212tOya5ux0ICQQPW3M7ML","authorship_tag":"ABX9TyMMyi0FqLqE/bUQiq10ZjN6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6ea4c0f93f1143e78613053e46587c12":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d8cdff2bd3be47de8975585c64e089b8","IPY_MODEL_22faba3e7ade48d2b050e266c2113391","IPY_MODEL_ebbcd990cad04e049e83e76c5dac7833"],"layout":"IPY_MODEL_4a8a98b4127141608901db4caa28daa5"}},"d8cdff2bd3be47de8975585c64e089b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd03d6fe9e17441b97cfe5a11317301a","placeholder":"​","style":"IPY_MODEL_4978153575d24be895259bba055d7582","value":"tokenizer.json: 100%"}},"22faba3e7ade48d2b050e266c2113391":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2d0706e59784258a71fb01a8adb5856","max":2825034,"min":0,"orientation":"horizontal","style":"IPY_MODEL_458b9d4eff5f4bd9a9c187e5faa1ff65","value":2825034}},"ebbcd990cad04e049e83e76c5dac7833":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d544f5b88774c638c9a48262c403857","placeholder":"​","style":"IPY_MODEL_6f487226dce747e087429904a3a0c52b","value":" 2.83M/2.83M [00:00&lt;00:00, 26.3MB/s]"}},"4a8a98b4127141608901db4caa28daa5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd03d6fe9e17441b97cfe5a11317301a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4978153575d24be895259bba055d7582":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2d0706e59784258a71fb01a8adb5856":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"458b9d4eff5f4bd9a9c187e5faa1ff65":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6d544f5b88774c638c9a48262c403857":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6f487226dce747e087429904a3a0c52b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d60f8f4ca0054487b1111bb87b6f3729":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65051b2c5d3d49e696ed8bfb8534cc08","IPY_MODEL_9e0659cf659b4f839e1eda58d6c3b1cd","IPY_MODEL_f1c349e18d7a46f58acbb52c5ae5c83f"],"layout":"IPY_MODEL_fc952e6d0e8c488eb610992f44316983"}},"65051b2c5d3d49e696ed8bfb8534cc08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_929e70ec5066451f882c52e9e73c493f","placeholder":"​","style":"IPY_MODEL_c9a7f7823f9147bb8472965634e289e4","value":"config.json: 100%"}},"9e0659cf659b4f839e1eda58d6c3b1cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c81022652664937a11f070d3ae2bb0a","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_977e54ce99274fafb32f819c1766121a","value":1000}},"f1c349e18d7a46f58acbb52c5ae5c83f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_81c8a61230244b5bacd9a65ad5efd8ef","placeholder":"​","style":"IPY_MODEL_14d84b51a446492c8b49149654a96493","value":" 1.00k/1.00k [00:00&lt;00:00, 37.4kB/s]"}},"fc952e6d0e8c488eb610992f44316983":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"929e70ec5066451f882c52e9e73c493f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9a7f7823f9147bb8472965634e289e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c81022652664937a11f070d3ae2bb0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"977e54ce99274fafb32f819c1766121a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"81c8a61230244b5bacd9a65ad5efd8ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14d84b51a446492c8b49149654a96493":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b869e5787f24623a4e268ac0533749e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8fa466f2cf844bb791466f55b91b9c38","IPY_MODEL_bd5755d71f7e4bd19e90734087822b23","IPY_MODEL_f98f0224a1f84781b460d873646b1fb8"],"layout":"IPY_MODEL_6ac63bd093334638b595c19541690b80"}},"8fa466f2cf844bb791466f55b91b9c38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d85900ca9eb446b9892868df4f53b76","placeholder":"​","style":"IPY_MODEL_897c895dbea44a56ab608dd86bfbf486","value":"pytorch_model.bin: 100%"}},"bd5755d71f7e4bd19e90734087822b23":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_900d2dd0d67d4a51baa559b50c3cc833","max":513302779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0d742b5a686e43b384188c24a2d0c179","value":513302779}},"f98f0224a1f84781b460d873646b1fb8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e405e93039014dfc91a8ff92a9d4aaab","placeholder":"​","style":"IPY_MODEL_5bfa38910ed84d579c5926adeef563eb","value":" 513M/513M [00:13&lt;00:00, 41.1MB/s]"}},"6ac63bd093334638b595c19541690b80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d85900ca9eb446b9892868df4f53b76":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"897c895dbea44a56ab608dd86bfbf486":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"900d2dd0d67d4a51baa559b50c3cc833":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d742b5a686e43b384188c24a2d0c179":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e405e93039014dfc91a8ff92a9d4aaab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bfa38910ed84d579c5926adeef563eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kOKMyQvkzihL"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","source":["!pip install openpyxl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFObt8VpOIUz","executionInfo":{"status":"ok","timestamp":1722391248455,"user_tz":-480,"elapsed":3160,"user":{"displayName":"hy j","userId":"15870501685188288436"}},"outputId":"3a2d8c49-1b33-411f-9051-0d44aacb17a1"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"]}]},{"cell_type":"code","source":["feed = pd.read_excel(\"/content/drive/MyDrive/자연어 처리 학습 피드백.xlsx\", names=[\"각도차이\", \"피드백\"])"],"metadata":{"id":"fwTDmyPQK4tQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tjHVsw7zOK6K","executionInfo":{"status":"ok","timestamp":1722218618498,"user_tz":-480,"elapsed":290,"user":{"displayName":"hy j","userId":"15870501685188288436"}},"outputId":"e6c861b2-30e5-4100-8e18-1794808affb0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                   각도차이  \\\n","0     [-20, 15, -18, 10, -5, 8, -12, 6]   \n","1      [8, -6, 12, -15, 20, -18, 7, -9]   \n","2     [-14, 10, -7, 5, -22, 17, -8, 13]   \n","3    [19, -11, 25, -13, 6, -9, 14, -16]   \n","4              [8, 1, 2, 4, 7, 3, 2, 1]   \n","5          [18, -24, -21, 13, 2, 3, 15]   \n","6       [12, 17, 11, 3, 4, -4, -7, -17]   \n","7      [-18, 5, 22, -7, 3, -16, 19, -4]   \n","8      [25, -20, 8, 17, -18, 6, -3, 21]   \n","9     [-4, 16, -23, 7, 19, -15, -17, 2]   \n","10    [12, -19, 5, -26, 17, 20, 8, -18]   \n","11     [-28, 7, 18, -3, -16, 9, 22, -5]   \n","12   [6, 24, -15, 19, -20, -7, -18, 13]   \n","13    [-17, -22, 9, 26, 4, 18, 15, -19]   \n","14    [21, 3, -25, -8, 16, -23, -5, 17]   \n","15   [-7, 18, 14, -21, -19, 5, 23, -16]   \n","16    [15, -26, -6, 20, 27, -4, -18, 9]   \n","17     [-23, 8, 19, -17, 6, 22, 4, -20]   \n","18   [28, -13, -24, 5, -18, -7, 16, 21]   \n","19    [-5, 25, 7, -22, 15, 19, -17, -3]   \n","20   [17, -19, 23, 12, -26, 8, 20, -15]   \n","21    [-20, 6, -16, 28, 9, -24, -4, 18]   \n","22    [7, -27, 13, -9, 22, 17, 25, -21]   \n","23   [-16, 19, -22, 4, -6, -18, 15, 26]   \n","24    [24, -8, 18, -25, 16, 5, -19, -7]   \n","25   [-3, 23, -15, 20, -28, 11, 6, -17]   \n","26   [19, -21, 27, -6, 7, -16, -23, 14]   \n","27    [-25, 9, -4, 16, 21, 23, 18, -20]   \n","28   [13, -18, 22, -27, -8, 15, -16, 5]   \n","29   [-14, 26, -19, 7, 17, -22, 24, -9]   \n","30    [20, -5, 15, 23, -25, 6, -21, 18]   \n","31   [-22, 16, -7, -19, 12, 28, 8, -26]   \n","32    [8, -24, 25, 3, -17, -13, 19, 21]   \n","33    [-15, 7, -23, 18, 26, 4, -20, -6]   \n","34   [27, -17, 11, -28, 9, 22, 16, -19]   \n","35   [-6, 25, 20, -4, -24, 15, -18, 13]   \n","36  [18, -11, -26, 21, 7, -21, 23, -16]   \n","37     [-28, 14, 6, -22, 19, 8, -5, 24]   \n","38    [16, -29, 22, 5, -18, 27, 20, -7]   \n","39       [1, -14, -13, 10, 7, 5, 6, -4]   \n","40        [3, 2, 7, 12, 11, 8, -11, -8]   \n","41          [-4, 2, 3, -7, 6, -2, 7, 0]   \n","42      [0, 4, -7, -13, 14, 12, 0, -14]   \n","43        [-1, 8, 12, 13, 11, 4, -3, 7]   \n","\n","                                                  피드백  \n","0        \"오른쪽 팔꿈치와 오른쪽 무릎을 더 펴주세요. 왼쪽 팔꿈치는 더 구부려주세요.\"  \n","1          \"왼쪽 무릎과 왼쪽 발목을을 더 펴주세요. 오른쪽 발목은 더 구부려주세요.\"  \n","2   \"오른쪽 팔꿈치를 조금 더 펴주세요. 왼쪽 팔꿈치를 조금 구부려주세요 오른쪽 발목은...  \n","3   \"오른쪽 팔꿈치와 오른쪽 무릎을 더 구부려주세요. 왼쪽 팔꿈치와 왼쪽 무릎과 왼쪽 ...  \n","4                          \"현재의 동작이 맞습니다. 이대로 유지하세요.\"  \n","5   \"오른쪽 팔꿈치와 왼쪽 골반을 더 구부려주세요. 왼쪽  팔꿈치와 오른쪽 무릎은 더 ...  \n","6                    \"왼쪽 팔꿈치는 더 구부려주시고 왼쪽 골반은 더 펴주세요\"  \n","7   \"오른쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎과 오른쪽 골반을 더 구부려주세요. 왼쪽...  \n","8   \"오른쪽 팔꿈치를 더 구부려주시고, 왼쪽 팔꿈치를 더 펴주세요. 왼쪽 무릎을 더 구...  \n","9   \"왼쪽 팔꿈치를 더 구부려주시고, 오른쪽 무릎을 더 펴주세요. 오른쪽 발목은 더 구...  \n","10  \"왼쪽 팔꿈치를 더 펴주세요. 왼쪽 무릎을 더 펴주세요. 오른쪽 발목과 왼쪽 발목을...  \n","11  \"오른쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎과 오른쪽 골반을 더 구부려주세요. 오른...  \n","12  \"왼쪽 팔꿈치와 왼쪽 무릎을 더 구부려주세요. 오른쪽 무릎은 더 펴주시고, 오른쪽 ...  \n","13  \"오른쪽 팔꿈치와 왼쪽 팔꿈치를 더 펴주세요. 왼쪽 무릎과 왼쪽 발목과 오른쪽 골반...  \n","14  \"오른쪽 팔꿈치를 더 구부려주시고, 오른쪽 무릎을 더 펴주세요. 오른쪽 발목은 더 ...  \n","15  \"왼쪽 팔꿈치를 더 구부려주시고, 왼쪽 무릎을 더 펴주세요. 오른쪽 발목은 더 펴주...  \n","16  \"오른쪽 팔꿈치를 조금 구부려주시고 왼쪽 팔꿈치를 더 펴주세요. 왼쪽 무릎과 오른쪽...  \n","17  \"오른쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎을 더 구부려주세요. 왼쪽 무릎은 더 펴...  \n","18  \"오른쪽 팔꿈치를 더 구부려주시고, 오른쪽 무릎을 더 펴주세요. 오른쪽 발목은 더 ...  \n","19  \"왼쪽 팔꿈치를 더 구부려주시고, 왼쪽 무릎을 더 펴주세요. 오른쪽 발목과 왼쪽 발...  \n","20  \"오른쪽 팔꿈치와 오른쪽 무릎을 더 구부려주시고, 왼쪽 팔꿈치를 더 펴주세요. 오른...  \n","21  \"오른쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎을 더 펴주세요. 왼쪽 무릎은 더 구부려...  \n","22  \"왼쪽 팔꿈치를 더 펴주세요. 오른쪽 발목과 왼쪽 발목을 더 구부려주시고 오른쪽 골...  \n","23  \"오른쪽 팔꿈치를 더 펴주시고, 왼쪽 팔꿈치를 더 구부려주세요. 오른쪽 무릎은 더 ...  \n","24  \"오른쪽 팔꿈치를 더 구부려주시고, 오른쪽 무릎을 더 구부려주세요. 왼쪽 무릎은 더...  \n","25  \"왼쪽 팔꿈치를 더 구부려주시고, 왼쪽 무릎을 더 구부려주세요. 오른쪽 발목을 더 ...  \n","26  \"오른쪽 팔꿈치와 오른쪽 무릎을 더 구부려주시고, 왼쪽 팔꿈치를 더 펴주세요. 왼쪽...  \n","27  \"오른쪽 팔꿈치를 더 펴주시고, 왼쪽 무릎을 더 구부려주세요. 오른쪽 발목과 왼쪽 ...  \n","28  \"왼쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎을 더 구부려주세요. 왼쪽 무릎은 더 펴주...  \n","29  \"왼쪽 팔꿈치를 더 구부려주세요. 오른쪽 무릎은 더 펴주시고 오른쪽 발목을 더 구부...  \n","30  \"오른쪽 팔꿈치를 더 구부려주시고, 왼쪽 무릎을 더 구부려주세요. 오른쪽 발목은 더...  \n","31  \"오른쪽 팔꿈치를 더 펴주시고, 왼쪽 팔꿈치를 더 구부려주세요. 왼쪽 무릎은 더 펴...  \n","32  \"왼쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎을 더 구부려주세요. 오른쪽 발목은 더 펴...  \n","33  \"오른쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎을 더 펴주세요. 왼쪽 무릎은 더 구부려...  \n","34  \"오른쪽 팔꿈치를 더 구부려주시고, 왼쪽 팔꿈치를 더 펴주세요. 왼쪽 무릎은 더 펴...  \n","35  \"왼쪽 팔꿈치와 오른쪽 무릎을 더 구부려주세요. 오른쪽 발목은 더 펴주시고 왼쪽 발...  \n","36  \"오른쪽 팔꿈치를 더 구부려주시고, 오른쪽 무릎을 더 펴주세요. 왼쪽 무릎은 더 구...  \n","37  \"오른쪽 팔꿈치를 더 펴주시고, 왼쪽 무릎을 더 펴주세요. 오른쪽 발목을 더 구부려...  \n","38  \"오른쪽 팔꿈치와 오른쪽 무릎을 더 구부려주시고, 왼쪽 팔꿈치는 더 펴주세요.오른쪽...  \n","39                         \"현재의 동작이 맞습니다. 이대로 유지하세요.\"  \n","40                         \"현재의 동작이 맞습니다. 이대로 유지하세요.\"  \n","41                         \"현재의 동작이 맞습니다. 이대로 유지하세요.\"  \n","42                         \"현재의 동작이 맞습니다. 이대로 유지하세요.\"  \n","43                         \"현재의 동작이 맞습니다. 이대로 유지하세요.\"  "],"text/html":["\n","  <div id=\"df-ee7c4dcf-1ae4-449c-ad8f-7ad89b441a8b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>각도차이</th>\n","      <th>피드백</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[-20, 15, -18, 10, -5, 8, -12, 6]</td>\n","      <td>\"오른쪽 팔꿈치와 오른쪽 무릎을 더 펴주세요. 왼쪽 팔꿈치는 더 구부려주세요.\"</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[8, -6, 12, -15, 20, -18, 7, -9]</td>\n","      <td>\"왼쪽 무릎과 왼쪽 발목을을 더 펴주세요. 오른쪽 발목은 더 구부려주세요.\"</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[-14, 10, -7, 5, -22, 17, -8, 13]</td>\n","      <td>\"오른쪽 팔꿈치를 조금 더 펴주세요. 왼쪽 팔꿈치를 조금 구부려주세요 오른쪽 발목은...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[19, -11, 25, -13, 6, -9, 14, -16]</td>\n","      <td>\"오른쪽 팔꿈치와 오른쪽 무릎을 더 구부려주세요. 왼쪽 팔꿈치와 왼쪽 무릎과 왼쪽 ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[8, 1, 2, 4, 7, 3, 2, 1]</td>\n","      <td>\"현재의 동작이 맞습니다. 이대로 유지하세요.\"</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>[18, -24, -21, 13, 2, 3, 15]</td>\n","      <td>\"오른쪽 팔꿈치와 왼쪽 골반을 더 구부려주세요. 왼쪽  팔꿈치와 오른쪽 무릎은 더 ...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>[12, 17, 11, 3, 4, -4, -7, -17]</td>\n","      <td>\"왼쪽 팔꿈치는 더 구부려주시고 왼쪽 골반은 더 펴주세요\"</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>[-18, 5, 22, -7, 3, -16, 19, -4]</td>\n","      <td>\"오른쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎과 오른쪽 골반을 더 구부려주세요. 왼쪽...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>[25, -20, 8, 17, -18, 6, -3, 21]</td>\n","      <td>\"오른쪽 팔꿈치를 더 구부려주시고, 왼쪽 팔꿈치를 더 펴주세요. 왼쪽 무릎을 더 구...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>[-4, 16, -23, 7, 19, -15, -17, 2]</td>\n","      <td>\"왼쪽 팔꿈치를 더 구부려주시고, 오른쪽 무릎을 더 펴주세요. 오른쪽 발목은 더 구...</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>[12, -19, 5, -26, 17, 20, 8, -18]</td>\n","      <td>\"왼쪽 팔꿈치를 더 펴주세요. 왼쪽 무릎을 더 펴주세요. 오른쪽 발목과 왼쪽 발목을...</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>[-28, 7, 18, -3, -16, 9, 22, -5]</td>\n","      <td>\"오른쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎과 오른쪽 골반을 더 구부려주세요. 오른...</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>[6, 24, -15, 19, -20, -7, -18, 13]</td>\n","      <td>\"왼쪽 팔꿈치와 왼쪽 무릎을 더 구부려주세요. 오른쪽 무릎은 더 펴주시고, 오른쪽 ...</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>[-17, -22, 9, 26, 4, 18, 15, -19]</td>\n","      <td>\"오른쪽 팔꿈치와 왼쪽 팔꿈치를 더 펴주세요. 왼쪽 무릎과 왼쪽 발목과 오른쪽 골반...</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>[21, 3, -25, -8, 16, -23, -5, 17]</td>\n","      <td>\"오른쪽 팔꿈치를 더 구부려주시고, 오른쪽 무릎을 더 펴주세요. 오른쪽 발목은 더 ...</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>[-7, 18, 14, -21, -19, 5, 23, -16]</td>\n","      <td>\"왼쪽 팔꿈치를 더 구부려주시고, 왼쪽 무릎을 더 펴주세요. 오른쪽 발목은 더 펴주...</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>[15, -26, -6, 20, 27, -4, -18, 9]</td>\n","      <td>\"오른쪽 팔꿈치를 조금 구부려주시고 왼쪽 팔꿈치를 더 펴주세요. 왼쪽 무릎과 오른쪽...</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>[-23, 8, 19, -17, 6, 22, 4, -20]</td>\n","      <td>\"오른쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎을 더 구부려주세요. 왼쪽 무릎은 더 펴...</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>[28, -13, -24, 5, -18, -7, 16, 21]</td>\n","      <td>\"오른쪽 팔꿈치를 더 구부려주시고, 오른쪽 무릎을 더 펴주세요. 오른쪽 발목은 더 ...</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>[-5, 25, 7, -22, 15, 19, -17, -3]</td>\n","      <td>\"왼쪽 팔꿈치를 더 구부려주시고, 왼쪽 무릎을 더 펴주세요. 오른쪽 발목과 왼쪽 발...</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>[17, -19, 23, 12, -26, 8, 20, -15]</td>\n","      <td>\"오른쪽 팔꿈치와 오른쪽 무릎을 더 구부려주시고, 왼쪽 팔꿈치를 더 펴주세요. 오른...</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>[-20, 6, -16, 28, 9, -24, -4, 18]</td>\n","      <td>\"오른쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎을 더 펴주세요. 왼쪽 무릎은 더 구부려...</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>[7, -27, 13, -9, 22, 17, 25, -21]</td>\n","      <td>\"왼쪽 팔꿈치를 더 펴주세요. 오른쪽 발목과 왼쪽 발목을 더 구부려주시고 오른쪽 골...</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>[-16, 19, -22, 4, -6, -18, 15, 26]</td>\n","      <td>\"오른쪽 팔꿈치를 더 펴주시고, 왼쪽 팔꿈치를 더 구부려주세요. 오른쪽 무릎은 더 ...</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>[24, -8, 18, -25, 16, 5, -19, -7]</td>\n","      <td>\"오른쪽 팔꿈치를 더 구부려주시고, 오른쪽 무릎을 더 구부려주세요. 왼쪽 무릎은 더...</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>[-3, 23, -15, 20, -28, 11, 6, -17]</td>\n","      <td>\"왼쪽 팔꿈치를 더 구부려주시고, 왼쪽 무릎을 더 구부려주세요. 오른쪽 발목을 더 ...</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>[19, -21, 27, -6, 7, -16, -23, 14]</td>\n","      <td>\"오른쪽 팔꿈치와 오른쪽 무릎을 더 구부려주시고, 왼쪽 팔꿈치를 더 펴주세요. 왼쪽...</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>[-25, 9, -4, 16, 21, 23, 18, -20]</td>\n","      <td>\"오른쪽 팔꿈치를 더 펴주시고, 왼쪽 무릎을 더 구부려주세요. 오른쪽 발목과 왼쪽 ...</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>[13, -18, 22, -27, -8, 15, -16, 5]</td>\n","      <td>\"왼쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎을 더 구부려주세요. 왼쪽 무릎은 더 펴주...</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>[-14, 26, -19, 7, 17, -22, 24, -9]</td>\n","      <td>\"왼쪽 팔꿈치를 더 구부려주세요. 오른쪽 무릎은 더 펴주시고 오른쪽 발목을 더 구부...</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>[20, -5, 15, 23, -25, 6, -21, 18]</td>\n","      <td>\"오른쪽 팔꿈치를 더 구부려주시고, 왼쪽 무릎을 더 구부려주세요. 오른쪽 발목은 더...</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>[-22, 16, -7, -19, 12, 28, 8, -26]</td>\n","      <td>\"오른쪽 팔꿈치를 더 펴주시고, 왼쪽 팔꿈치를 더 구부려주세요. 왼쪽 무릎은 더 펴...</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>[8, -24, 25, 3, -17, -13, 19, 21]</td>\n","      <td>\"왼쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎을 더 구부려주세요. 오른쪽 발목은 더 펴...</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>[-15, 7, -23, 18, 26, 4, -20, -6]</td>\n","      <td>\"오른쪽 팔꿈치를 더 펴주시고, 오른쪽 무릎을 더 펴주세요. 왼쪽 무릎은 더 구부려...</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>[27, -17, 11, -28, 9, 22, 16, -19]</td>\n","      <td>\"오른쪽 팔꿈치를 더 구부려주시고, 왼쪽 팔꿈치를 더 펴주세요. 왼쪽 무릎은 더 펴...</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>[-6, 25, 20, -4, -24, 15, -18, 13]</td>\n","      <td>\"왼쪽 팔꿈치와 오른쪽 무릎을 더 구부려주세요. 오른쪽 발목은 더 펴주시고 왼쪽 발...</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>[18, -11, -26, 21, 7, -21, 23, -16]</td>\n","      <td>\"오른쪽 팔꿈치를 더 구부려주시고, 오른쪽 무릎을 더 펴주세요. 왼쪽 무릎은 더 구...</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>[-28, 14, 6, -22, 19, 8, -5, 24]</td>\n","      <td>\"오른쪽 팔꿈치를 더 펴주시고, 왼쪽 무릎을 더 펴주세요. 오른쪽 발목을 더 구부려...</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>[16, -29, 22, 5, -18, 27, 20, -7]</td>\n","      <td>\"오른쪽 팔꿈치와 오른쪽 무릎을 더 구부려주시고, 왼쪽 팔꿈치는 더 펴주세요.오른쪽...</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>[1, -14, -13, 10, 7, 5, 6, -4]</td>\n","      <td>\"현재의 동작이 맞습니다. 이대로 유지하세요.\"</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>[3, 2, 7, 12, 11, 8, -11, -8]</td>\n","      <td>\"현재의 동작이 맞습니다. 이대로 유지하세요.\"</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>[-4, 2, 3, -7, 6, -2, 7, 0]</td>\n","      <td>\"현재의 동작이 맞습니다. 이대로 유지하세요.\"</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>[0, 4, -7, -13, 14, 12, 0, -14]</td>\n","      <td>\"현재의 동작이 맞습니다. 이대로 유지하세요.\"</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>[-1, 8, 12, 13, 11, 4, -3, 7]</td>\n","      <td>\"현재의 동작이 맞습니다. 이대로 유지하세요.\"</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee7c4dcf-1ae4-449c-ad8f-7ad89b441a8b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ee7c4dcf-1ae4-449c-ad8f-7ad89b441a8b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ee7c4dcf-1ae4-449c-ad8f-7ad89b441a8b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-de1dcac1-5754-44d2-8e7a-a5f8ed06a775\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-de1dcac1-5754-44d2-8e7a-a5f8ed06a775')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-de1dcac1-5754-44d2-8e7a-a5f8ed06a775 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_ebed794f-cf51-475b-b909-1ff3de77c261\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('feed')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_ebed794f-cf51-475b-b909-1ff3de77c261 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('feed');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"feed","summary":"{\n  \"name\": \"feed\",\n  \"rows\": 44,\n  \"fields\": [\n    {\n      \"column\": \"\\uac01\\ub3c4\\ucc28\\uc774\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 44,\n        \"samples\": [\n          \"[-28, 14, 6, -22, 19, 8, -5, 24]\",\n          \"[24, -8, 18, -25, 16, 5, -19, -7]\",\n          \"[-3, 23, -15, 20, -28, 11, 6, -17]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\ud53c\\ub4dc\\ubc31\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39,\n        \"samples\": [\n          \"\\\"\\uc624\\ub978\\ucabd \\ud314\\uafc8\\uce58\\ub97c \\ub354 \\ud3b4\\uc8fc\\uc2dc\\uace0, \\uc624\\ub978\\ucabd \\ubb34\\ub98e\\uc744 \\ub354 \\ud3b4\\uc8fc\\uc138\\uc694. \\uc67c\\ucabd \\ubb34\\ub98e\\uc740 \\ub354 \\uad6c\\ubd80\\ub824\\uc8fc\\uc2dc\\uace0 \\uc624\\ub978\\ucabd \\ubc1c\\ubaa9\\uc744 \\ub354 \\uad6c\\ubd80\\ub824\\uc8fc\\uc138\\uc694. \\uc624\\ub978\\ucabd \\uace8\\ubc18\\uc740 \\ub354 \\ud3b4\\uc8fc\\uc138\\uc694.\\\"\",\n          \"\\\"\\uc624\\ub978\\ucabd \\ud314\\uafc8\\uce58\\ub97c \\ub354 \\uad6c\\ubd80\\ub824\\uc8fc\\uc2dc\\uace0, \\uc624\\ub978\\ucabd \\ubb34\\ub98e\\uc744 \\ub354 \\ud3b4\\uc8fc\\uc138\\uc694. \\uc67c\\ucabd \\ubb34\\ub98e\\uc740 \\ub354 \\uad6c\\ubd80\\ub824\\uc8fc\\uc2dc\\uace0 \\uc67c\\ucabd \\ubc1c\\ubaa9\\uc744 \\ub354 \\ud3b4\\uc8fc\\uc138\\uc694. \\uc624\\ub978\\ucabd \\uace8\\ubc18\\uc744 \\ub354 \\uad6c\\ubd80\\ub824\\uc8fc\\uc2dc\\uace0 \\uc67c\\ucabd \\uace8\\ubc18\\uc744 \\ub354 \\ud3b4\\uc8fc\\uc138\\uc694.\\\"\",\n          \"\\\"\\ud604\\uc7ac\\uc758 \\ub3d9\\uc791\\uc774 \\ub9de\\uc2b5\\ub2c8\\ub2e4. \\uc774\\ub300\\ub85c \\uc720\\uc9c0\\ud558\\uc138\\uc694.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["feed.loc[:, \"각도차이\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KUVEekOlQdaT","executionInfo":{"status":"ok","timestamp":1722219193257,"user_tz":-480,"elapsed":277,"user":{"displayName":"hy j","userId":"15870501685188288436"}},"outputId":"34a2aed4-6ea2-4a0f-995f-75b064f52fb8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0       [-20, 15, -18, 10, -5, 8, -12, 6]\n","1        [8, -6, 12, -15, 20, -18, 7, -9]\n","2       [-14, 10, -7, 5, -22, 17, -8, 13]\n","3      [19, -11, 25, -13, 6, -9, 14, -16]\n","4                [8, 1, 2, 4, 7, 3, 2, 1]\n","5            [18, -24, -21, 13, 2, 3, 15]\n","6         [12, 17, 11, 3, 4, -4, -7, -17]\n","7        [-18, 5, 22, -7, 3, -16, 19, -4]\n","8        [25, -20, 8, 17, -18, 6, -3, 21]\n","9       [-4, 16, -23, 7, 19, -15, -17, 2]\n","10      [12, -19, 5, -26, 17, 20, 8, -18]\n","11       [-28, 7, 18, -3, -16, 9, 22, -5]\n","12     [6, 24, -15, 19, -20, -7, -18, 13]\n","13      [-17, -22, 9, 26, 4, 18, 15, -19]\n","14      [21, 3, -25, -8, 16, -23, -5, 17]\n","15     [-7, 18, 14, -21, -19, 5, 23, -16]\n","16      [15, -26, -6, 20, 27, -4, -18, 9]\n","17       [-23, 8, 19, -17, 6, 22, 4, -20]\n","18     [28, -13, -24, 5, -18, -7, 16, 21]\n","19      [-5, 25, 7, -22, 15, 19, -17, -3]\n","20     [17, -19, 23, 12, -26, 8, 20, -15]\n","21      [-20, 6, -16, 28, 9, -24, -4, 18]\n","22      [7, -27, 13, -9, 22, 17, 25, -21]\n","23     [-16, 19, -22, 4, -6, -18, 15, 26]\n","24      [24, -8, 18, -25, 16, 5, -19, -7]\n","25     [-3, 23, -15, 20, -28, 11, 6, -17]\n","26     [19, -21, 27, -6, 7, -16, -23, 14]\n","27      [-25, 9, -4, 16, 21, 23, 18, -20]\n","28     [13, -18, 22, -27, -8, 15, -16, 5]\n","29     [-14, 26, -19, 7, 17, -22, 24, -9]\n","30      [20, -5, 15, 23, -25, 6, -21, 18]\n","31     [-22, 16, -7, -19, 12, 28, 8, -26]\n","32      [8, -24, 25, 3, -17, -13, 19, 21]\n","33      [-15, 7, -23, 18, 26, 4, -20, -6]\n","34     [27, -17, 11, -28, 9, 22, 16, -19]\n","35     [-6, 25, 20, -4, -24, 15, -18, 13]\n","36    [18, -11, -26, 21, 7, -21, 23, -16]\n","37       [-28, 14, 6, -22, 19, 8, -5, 24]\n","38      [16, -29, 22, 5, -18, 27, 20, -7]\n","39         [1, -14, -13, 10, 7, 5, 6, -4]\n","40          [3, 2, 7, 12, 11, 8, -11, -8]\n","41            [-4, 2, 3, -7, 6, -2, 7, 0]\n","42        [0, 4, -7, -13, 14, 12, 0, -14]\n","43          [-1, 8, 12, 13, 11, 4, -3, 7]\n","Name: 각도차이, dtype: object"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":549},"id":"tMe32rjb1xS5","executionInfo":{"status":"error","timestamp":1722228010415,"user_tz":-480,"elapsed":26664,"user":{"displayName":"hy j","userId":"15870501685188288436"}},"outputId":"418ca32a-a12d-48bd-b93b-9d117cd13da4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.9.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'lm_head.weight']\n","- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/500, Loss: [nan]\n","Validation Loss: [nan]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-f8696b233c76>\u001b[0m in \u001b[0;36m<cell line: 100>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_dataset)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-35-f8696b233c76>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(input_ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1710\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m     \u001b[0mgrad_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[0;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[1;32m   6169\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6170\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6171\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   6172\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MatMul\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_a\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transpose_b\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6173\u001b[0m         transpose_b)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"scUNMfC3KyFR","executionInfo":{"status":"ok","timestamp":1722227973044,"user_tz":-480,"elapsed":13279,"user":{"displayName":"hy j","userId":"15870501685188288436"}},"outputId":"fa319811-efdd-435d-8c07-bf00ce211820"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from transformers import PreTrainedTokenizerFast, TFGPT2LMHeadModel\n","import numpy as np\n","import json\n","import pandas as pd  # pandas 추가\n","\n","# KoGPT2 모델과 토크나이저 로드\n","model_name = 'skt/kogpt2-base-v2'\n","tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name, bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>')\n","model = TFGPT2LMHeadModel.from_pretrained(model_name, from_pt=True)\n","model.config.use_cache = False  # 캐시 사용 비활성화\n","\n","# 데이터 로드 (feed 데이터프레임을 CSV 파일에서 로드한다고 가정)\n","feed = pd.read_excel(\"/content/drive/MyDrive/자연어 처리 학습 피드백.xlsx\", names=[\"각도차이\", \"피드백\"])  # CSV 파일 이름을 적절히 변경하세요\n","angle_differences = feed.loc[:, \"각도차이\"].apply(eval)  # 문자열을 리스트로 변환\n","feedbacks = feed.loc[:, \"피드백\"]\n","\n","# 각도 차이 데이터를 풀어서 1차원 배열로 만듭니다\n","angle_differences_flat = [angle for angles in angle_differences for angle in angles]\n","\n","# 1차원 배열에 대해 정규화를 수행합니다\n","angle_differences_normalized = (np.array(angle_differences_flat) - np.mean(angle_differences_flat)) / np.std(angle_differences_flat)\n","\n","# 정규화된 값을 다시 원래의 리스트 구조로 재구성합니다\n","start = 0\n","angle_differences_normalized_list = []\n","for angles in angle_differences:\n","    end = start + len(angles)\n","    angle_differences_normalized_list.append(angle_differences_normalized[start:end].tolist())\n","    start = end\n","\n","# 데이터 준비 및 JSON 파일로 저장\n","data = []\n","for angles, feedback in zip(angle_differences_normalized_list, feedbacks):\n","    angle_str = ' '.join([f\"{angle:.2f}\" for angle in angles])\n","    prompt = f\"각도 차이: {angle_str}\"\n","    item = {\n","        \"prompt\": prompt,\n","        \"completion\": feedback\n","    }\n","    data.append(item)\n","\n","with open('training_data.json', 'w', encoding='utf-8') as f:\n","    json.dump(data, f, ensure_ascii=False, indent=2)\n","\n","# 데이터 전처리 함수\n","def preprocess_data(data, max_length=128):\n","    inputs = []\n","    labels = []\n","    for item in data:\n","        prompt = item['prompt']\n","        completion = item['completion']\n","        text = f\"{prompt} 피드백: {completion}\"\n","        inputs.append(text)\n","        labels.append(completion)\n","\n","    # 입력 인코딩\n","    input_encodings = tokenizer(inputs, truncation=True, padding='max_length', max_length=max_length, return_tensors=\"tf\")\n","    input_ids = input_encodings['input_ids']\n","    attention_mask = input_encodings['attention_mask']\n","\n","    # 레이블 인코딩\n","    label_encodings = tokenizer(labels, truncation=True, padding='max_length', max_length=max_length, return_tensors=\"tf\")\n","    label_ids = label_encodings['input_ids']\n","\n","    # 레이블에서 prompt 부분을 -100으로 마스킹\n","    prompt_lengths = [len(tokenizer.encode(input_text.split('피드백:')[0])) for input_text in inputs]\n","    mask = tf.sequence_mask(prompt_lengths, maxlen=max_length)\n","    label_ids = tf.where(mask, tf.constant(-100, shape=label_ids.shape), label_ids)\n","\n","    # 패딩 토큰을 -100으로 변경\n","    label_ids = tf.where(label_ids == tokenizer.pad_token_id, -100, label_ids)\n","\n","    return input_ids, attention_mask, label_ids\n","\n","# 데이터 로드 및 전처리\n","with open('training_data.json', 'r', encoding='utf-8') as f:\n","    training_data = json.load(f)\n","\n","input_ids, attention_mask, labels = preprocess_data(training_data)\n","\n","# TensorFlow 데이터셋 생성\n","tf_dataset = tf.data.Dataset.from_tensor_slices((\n","    {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n","    {\"labels\": labels}\n","))\n","\n","# 데이터셋 분할 및 배치 설정\n","train_size = int(0.9 * len(tf_dataset))\n","tf_dataset = tf_dataset.shuffle(len(tf_dataset))\n","train_dataset = tf_dataset.take(train_size).batch(8)\n","val_dataset = tf_dataset.skip(train_size).batch(8)\n","\n","# 학습률 스케줄러 및 옵티마이저 설정\n","lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate=5e-5,\n","    decay_steps=1000,\n","    decay_rate=0.9)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n","\n","# 커스텀 손실 함수\n","def custom_loss(labels, logits):\n","    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","    mask = tf.not_equal(labels, -100)\n","    labels = tf.boolean_mask(labels, mask)\n","    logits = tf.boolean_mask(logits, mask)\n","    return loss_fn(labels, logits)\n","\n","model.compile(optimizer=optimizer, loss=custom_loss)\n","\n","# 학습 스텝 함수\n","@tf.function\n","def train_step(input_ids, attention_mask, labels):\n","    with tf.GradientTape() as tape:\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels, training=True)\n","        loss = outputs.loss\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    gradients, _ = tf.clip_by_global_norm(gradients, 1.0)  # 그래디언트 클리핑\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    return loss\n","\n","# 학습 루프\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    total_loss = 0\n","    for batch in train_dataset:\n","        inputs, labels = batch\n","        loss = train_step(inputs['input_ids'], inputs['attention_mask'], labels['labels'])\n","        total_loss += loss\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(train_dataset)}\")\n","\n","    # 검증\n","    val_loss = 0\n","    for batch in val_dataset:\n","        inputs, labels = batch\n","        outputs = model(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], labels=labels['labels'])\n","        val_loss += outputs.loss\n","    print(f\"Validation Loss: {val_loss/len(val_dataset)}\")\n","\n","# 모델 저장\n","model.save_pretrained(\"./fine_tuned_kogpt2_tf\")\n","tokenizer.save_pretrained(\"./fine_tuned_kogpt2_tf\")\n","\n","# 새로운 각도 차이에 대한 피드백 생성 함수\n","def generate_feedback(model, tokenizer, angle_differences, max_length=100):\n","    # 입력 각도 차이 정규화\n","    normalized_angles = (angle_differences - np.mean(angle_differences_flat)) / np.std(angle_differences_flat)\n","    angle_str = ' '.join([f\"{angle:.2f}\" for angle in normalized_angles])\n","    input_text = f\"다음 각도 차이에 대한 자세 피드백을 생성해주세요: {angle_str}\\n피드백:\"\n","    input_ids = tokenizer.encode(input_text, return_tensors='tf')\n","\n","    output = model.generate(\n","    input_ids,\n","    max_length=max_length,\n","    num_return_sequences=1,\n","    no_repeat_ngram_size=2,\n","    do_sample=True,\n","    temperature=0.8,  # 0.7에서 약간 높임\n","    top_k=40,  # 50에서 낮춤\n","    top_p=0.92,  # 0.95에서 낮춤\n","    eos_token_id=tokenizer.eos_token_id,\n","    pad_token_id=tokenizer.pad_token_id,\n","    )\n","\n","    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n","    feedback = generated_text.split(\"피드백:\")[1].strip()\n","\n","    return feedback\n","\n","# 새로운 각도 차이에 대한 피드백 생성 예시\n","new_angle_differences = [16, -15, 23, -16, 24, -16, 12, -18]\n","feedback = generate_feedback(model, tokenizer, new_angle_differences)\n","print(f\"새로운 각도 차이: {new_angle_differences}\")\n","print(f\"생성된 피드백: {feedback}\")"],"metadata":{"id":"4B19AD2b7uKO","colab":{"base_uri":"https://localhost:8080/","height":715,"referenced_widgets":["6ea4c0f93f1143e78613053e46587c12","d8cdff2bd3be47de8975585c64e089b8","22faba3e7ade48d2b050e266c2113391","ebbcd990cad04e049e83e76c5dac7833","4a8a98b4127141608901db4caa28daa5","fd03d6fe9e17441b97cfe5a11317301a","4978153575d24be895259bba055d7582","d2d0706e59784258a71fb01a8adb5856","458b9d4eff5f4bd9a9c187e5faa1ff65","6d544f5b88774c638c9a48262c403857","6f487226dce747e087429904a3a0c52b","d60f8f4ca0054487b1111bb87b6f3729","65051b2c5d3d49e696ed8bfb8534cc08","9e0659cf659b4f839e1eda58d6c3b1cd","f1c349e18d7a46f58acbb52c5ae5c83f","fc952e6d0e8c488eb610992f44316983","929e70ec5066451f882c52e9e73c493f","c9a7f7823f9147bb8472965634e289e4","2c81022652664937a11f070d3ae2bb0a","977e54ce99274fafb32f819c1766121a","81c8a61230244b5bacd9a65ad5efd8ef","14d84b51a446492c8b49149654a96493","9b869e5787f24623a4e268ac0533749e","8fa466f2cf844bb791466f55b91b9c38","bd5755d71f7e4bd19e90734087822b23","f98f0224a1f84781b460d873646b1fb8","6ac63bd093334638b595c19541690b80","4d85900ca9eb446b9892868df4f53b76","897c895dbea44a56ab608dd86bfbf486","900d2dd0d67d4a51baa559b50c3cc833","0d742b5a686e43b384188c24a2d0c179","e405e93039014dfc91a8ff92a9d4aaab","5bfa38910ed84d579c5926adeef563eb"]},"executionInfo":{"status":"error","timestamp":1722303287242,"user_tz":-480,"elapsed":180262,"user":{"displayName":"hy j","userId":"15870501685188288436"}},"outputId":"fd78ffb6-8d58-4ca6-af80-6b60eb7ca956"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ea4c0f93f1143e78613053e46587c12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d60f8f4ca0054487b1111bb87b6f3729"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b869e5787f24623a4e268ac0533749e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.6.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'lm_head.weight', 'transformer.h.4.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.11.attn.masked_bias']\n","- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"]},{"output_type":"error","ename":"ValueError","evalue":"Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x7d01c2b32a70>","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-f243f14f76e1>\u001b[0m in \u001b[0;36m<cell line: 109>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;31m# 학습 스텝 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_tf_utils.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[1;32m   1561\u001b[0m         \u001b[0;31m# This argument got renamed, we need to support both versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"steps_per_execution\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparent_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m             super().compile(\n\u001b[0m\u001b[1;32m   1564\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tf_keras/src/optimizers/__init__.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m         )\n\u001b[1;32m    333\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;34mf\"Could not interpret optimizer identifier: {identifier}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         )\n","\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x7d01c2b32a70>"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Attention\n","\n","# 데이터 로드\n","df = pd.read_excel(\"/content/drive/MyDrive/자연어 처리 학습 피드백.xlsx\", names=[\"각도차이\", \"피드백\"])\n","angle_differences = df.loc[:, \"각도차이\"].apply(eval).tolist()\n","feedbacks = df.loc[:, \"피드백\"].tolist()\n","\n","# 데이터 증강\n","def augment_data(angles, feedbacks):\n","    augmented_angles = []\n","    augmented_feedbacks = []\n","    for angle, feedback in zip(angles, feedbacks):\n","        # 원본 데이터 추가\n","        augmented_angles.append(angle)\n","        augmented_feedbacks.append(feedback)\n","\n","        # 각도에 작은 노이즈 추가\n","        noisy_angle = [a + np.random.normal(0, 2) for a in angle]\n","        augmented_angles.append(noisy_angle)\n","        augmented_feedbacks.append(feedback)\n","\n","        # 각도 순서 뒤집기\n","        reversed_angle = angle[::-1]\n","        augmented_angles.append(reversed_angle)\n","        augmented_feedbacks.append(feedback)\n","\n","    return augmented_angles, augmented_feedbacks\n","\n","angle_differences, feedbacks = augment_data(angle_differences, feedbacks)\n","\n","# 데이터 전처리\n","def preprocess_data(angles, feedbacks):\n","    angle_tensor = tf.keras.preprocessing.sequence.pad_sequences(angles, padding='post')\n","    angle_tensor = np.expand_dims(angle_tensor, axis=-1)\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token=\"<UNK>\")  # oov_token 추가\n","    tokenizer.fit_on_texts(['<start> ' + f + ' <end>' for f in feedbacks])\n","    feedback_tensor = tokenizer.texts_to_sequences(['<start> ' + f + ' <end>' for f in feedbacks])\n","    feedback_tensor = tf.keras.preprocessing.sequence.pad_sequences(feedback_tensor, padding='post')\n","    return angle_tensor, feedback_tensor, tokenizer\n","\n","angle_tensor, feedback_tensor, tokenizer = preprocess_data(angle_differences, feedbacks)\n","# 데이터 분할 전에 텐서를 NumPy 배열로 변환\n","X = angle_tensor.numpy() if isinstance(angle_tensor, tf.Tensor) else angle_tensor\n","y = feedback_tensor.numpy() if isinstance(feedback_tensor, tf.Tensor) else feedback_tensor\n","\n","# 데이터 분할\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 분할된 데이터를 다시 텐서로 변환\n","X_train = tf.convert_to_tensor(X_train)\n","X_test = tf.convert_to_tensor(X_test)\n","y_train = tf.convert_to_tensor(y_train)\n","y_test = tf.convert_to_tensor(y_test)\n","# 모델 정의 (with Attention)\n","class Seq2SeqAttentionModel(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, units):\n","        super(Seq2SeqAttentionModel, self).__init__()\n","        self.encoder_input = Input(shape=(None, 1))  # Add this line\n","        self.decoder_input = Input(shape=(None,))    # Add this line\n","        self.embedding = Embedding(vocab_size, embedding_dim)\n","        self.encoder = LSTM(units, return_sequences=True, return_state=True)\n","        self.decoder = LSTM(units, return_sequences=True, return_state=True)\n","        self.attention = Attention()\n","        self.dense = Dense(vocab_size)\n","\n","    def call(self, inputs, training=False):\n","        encoder_input, decoder_input = inputs\n","        encoder_input = tf.cast(encoder_input, tf.float32)  # 입력을 float32로 변환\n","\n","        encoder_output = self.encoder(encoder_input)[0]\n","\n","        decoder_hidden = self.embedding(decoder_input)\n","        decoder_output = self.decoder(decoder_hidden)[0]\n","\n","        context_vector = self.attention([decoder_output, encoder_output])\n","        decoder_combined_context = tf.concat([context_vector, decoder_output], axis=-1)\n","\n","        output = self.dense(decoder_combined_context)\n","        return output\n","\n","# 하이퍼파라미터\n","vocab_size = len(tokenizer.word_index) + 1\n","embedding_dim = 256\n","units = 512\n","batch_size = 64\n","epochs = 100\n","\n","# 모델 컴파일\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model = Seq2SeqAttentionModel(vocab_size, embedding_dim, units)\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')\n","model.build(input_shape=[(None, 8, 1), (None, None)])\n","# 모델 학습\n","early_stopping = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n","history = model.fit([X_train, y_train[:, :-1]], y_train[:, 1:],\n","                    validation_split=0.2,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    callbacks=[early_stopping])\n","\n","# 피드백 생성 함수\n","def generate_feedback(model, tokenizer, angles):\n","    angle_tensor = tf.keras.preprocessing.sequence.pad_sequences([angles], padding='post')\n","    angle_tensor = tf.expand_dims(angle_tensor, axis=-1)\n","    start_token = tokenizer.word_index['<start>']\n","    end_token = tokenizer.word_index['<end>']\n","\n","    decoder_input = tf.constant([[start_token]])\n","    result = []\n","\n","    for _ in range(50):  # 최대 50 단어 생성\n","        predictions = model([angle_tensor, decoder_input])\n","        predicted_id = tf.argmax(predictions[0, -1, :])  # 변경된 부분\n","        predicted_id = int(predicted_id)\n","\n","        if predicted_id == end_token:\n","            break\n","\n","        if predicted_id in tokenizer.index_word:\n","            result.append(tokenizer.index_word[predicted_id])\n","        else:\n","            result.append(\"<UNK>\")  # 알 수 없는 단어를 위한 토큰\n","\n","        decoder_input = tf.concat([decoder_input, [[predicted_id]]], axis=1)  # 변경된 부분\n","\n","    return ' '.join(result)\n","# 테스트\n","test_angles = [16, -29, 22, 5, -18, 27, 20, -7]\n","generated_feedback = generate_feedback(model, tokenizer, test_angles)\n","print(f\"입력 각도: {test_angles}\")\n","print(f\"생성된 피드백: {generated_feedback}\")\n","\n","# 모델 평가\n","test_loss = model.evaluate([X_test, y_test[:, :-1]], y_test[:, 1:])\n","print(f\"Test Loss: {test_loss}\")"],"metadata":{"id":"juKn11rrSOOh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722301243625,"user_tz":-480,"elapsed":36042,"user":{"displayName":"hy j","userId":"15870501685188288436"}},"outputId":"d9302d9c-1de1-4d7b-c30d-1404268ea83b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","2/2 [==============================] - 14s 2s/step - loss: 9.2829 - val_loss: 5.0156\n","Epoch 2/100\n","2/2 [==============================] - 1s 562ms/step - loss: 4.9131 - val_loss: 4.4704\n","Epoch 3/100\n","2/2 [==============================] - 2s 933ms/step - loss: 4.5842 - val_loss: 4.4455\n","Epoch 4/100\n","2/2 [==============================] - 2s 875ms/step - loss: 4.5359 - val_loss: 4.4223\n","Epoch 5/100\n","2/2 [==============================] - 2s 1s/step - loss: 4.5173 - val_loss: 4.3711\n","Epoch 6/100\n","2/2 [==============================] - 1s 397ms/step - loss: 4.4567 - val_loss: 4.3107\n","Epoch 7/100\n","2/2 [==============================] - 1s 400ms/step - loss: 4.3843 - val_loss: 4.2199\n","Epoch 8/100\n","2/2 [==============================] - 1s 394ms/step - loss: 4.2624 - val_loss: 4.4544\n","Epoch 9/100\n","2/2 [==============================] - 1s 391ms/step - loss: 4.2490 - val_loss: 4.2705\n","Epoch 10/100\n","2/2 [==============================] - 1s 416ms/step - loss: 4.1499 - val_loss: 4.2691\n","Epoch 11/100\n","2/2 [==============================] - 1s 381ms/step - loss: 4.1402 - val_loss: 4.4697\n","Epoch 12/100\n","2/2 [==============================] - 1s 403ms/step - loss: 4.2189 - val_loss: 4.3062\n","입력 각도: [16, -29, 22, 5, -18, 27, 20, -7]\n","생성된 피드백: <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK>\n","1/1 [==============================] - 0s 175ms/step - loss: 4.4614\n","Test Loss: 4.4613518714904785\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n","\n","# 데이터 로드\n","df = pd.read_excel(\"/content/drive/MyDrive/자연어 처리 학습 피드백.xlsx\", names=[\"각도차이\", \"피드백\"])\n","angle_differences = df.loc[:, \"각도차이\"].apply(eval).tolist()\n","feedbacks = df.loc[:, \"피드백\"].tolist()\n","\n","# 데이터 증강 (강화)\n","def augment_data(angles, feedbacks):\n","    augmented_angles = []\n","    augmented_feedbacks = []\n","    for angle, feedback in zip(angles, feedbacks):\n","        # 원본 데이터 추가\n","        augmented_angles.append(angle)\n","        augmented_feedbacks.append(feedback)\n","\n","        # 각도에 작은 노이즈 추가 (3번)\n","        for _ in range(3):\n","            noisy_angle = [a + np.random.normal(0, 2) for a in angle]\n","            augmented_angles.append(noisy_angle)\n","            augmented_feedbacks.append(feedback)\n","\n","\n","    return augmented_angles, augmented_feedbacks\n","\n","angle_differences, feedbacks = augment_data(angle_differences, feedbacks)\n","\n","# 데이터 전처리\n","def preprocess_data(angles, feedbacks):\n","    angle_tensor = tf.keras.preprocessing.sequence.pad_sequences(angles, padding='post')\n","    angle_tensor = np.expand_dims(angle_tensor, axis=-1)\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', lower=True, oov_token=\"<UNK>\")\n","    tokenizer.fit_on_texts(['<start> ' + f.lower() + ' <end>' for f in feedbacks])\n","    feedback_tensor = tokenizer.texts_to_sequences(['<start> ' + f.lower() + ' <end>' for f in feedbacks])\n","    feedback_tensor = tf.keras.preprocessing.sequence.pad_sequences(feedback_tensor, padding='post')\n","    return angle_tensor, feedback_tensor, tokenizer\n","\n","angle_tensor, feedback_tensor, tokenizer = preprocess_data(angle_differences, feedbacks)\n","\n","# 데이터 분할\n","X = angle_tensor.numpy() if isinstance(angle_tensor, tf.Tensor) else angle_tensor\n","y = feedback_tensor.numpy() if isinstance(feedback_tensor, tf.Tensor) else feedback_tensor\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train = tf.convert_to_tensor(X_train)\n","X_test = tf.convert_to_tensor(X_test)\n","y_train = tf.convert_to_tensor(y_train)\n","y_test = tf.convert_to_tensor(y_test)\n","\n","# 모델 정의\n","class Seq2SeqModel(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, units):\n","        super(Seq2SeqModel, self).__init__()\n","        self.encoder_input = Input(shape=(None, 1))\n","        self.decoder_input = Input(shape=(None,))\n","        self.embedding = Embedding(vocab_size, embedding_dim)\n","        self.encoder = LSTM(units, return_sequences=True, return_state=True)\n","        self.decoder = LSTM(units, return_sequences=True, return_state=True)\n","        self.dropout = Dropout(0.3)\n","        self.dense = Dense(vocab_size)\n","\n","    def call(self, inputs, training=False):\n","        encoder_input, decoder_input = inputs\n","        encoder_input = tf.cast(encoder_input, tf.float32)\n","\n","        encoder_output, state_h, state_c = self.encoder(encoder_input)\n","\n","        decoder_hidden = self.embedding(decoder_input)\n","        decoder_output, _, _ = self.decoder(decoder_hidden, initial_state=[state_h, state_c])\n","\n","        decoder_output = self.dropout(decoder_output, training=training)\n","        output = self.dense(decoder_output)\n","        return output\n","\n","# 하이퍼파라미터\n","vocab_size = len(tokenizer.word_index) + 1\n","embedding_dim = 256  # 감소\n","units = 128  # 감소\n","batch_size = 4  # 감소\n","epochs = 100\n","\n","# 모델 컴파일\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.002)  # 학습률 감소\n","model = Seq2SeqModel(vocab_size, embedding_dim, units)\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy')\n","model.build(input_shape=[(None, 8, 1), (None, None)])\n","\n","# 모델 학습\n","early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n","history = model.fit([X_train, y_train[:, :-1]], y_train[:, 1:],\n","                    validation_split=0.2,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    callbacks=[early_stopping])\n","\n","# 피드백 생성 함수\n","def generate_feedback(model, tokenizer, angles):\n","    angle_tensor = tf.keras.preprocessing.sequence.pad_sequences([angles], padding='post')\n","    angle_tensor = tf.expand_dims(angle_tensor, axis=-1)\n","    start_token = tokenizer.word_index['<start>']\n","    end_token = tokenizer.word_index['<end>']\n","\n","    decoder_input = tf.constant([[start_token]])\n","    result = []\n","\n","    for _ in range(50):\n","        predictions = model([angle_tensor, decoder_input])\n","        predicted_id = tf.argmax(predictions[0, -1, :])\n","        predicted_id = int(predicted_id)\n","\n","        if predicted_id == end_token:\n","            break\n","\n","        if predicted_id in tokenizer.index_word:\n","            result.append(tokenizer.index_word[predicted_id])\n","        else:\n","            result.append(\"<UNK>\")\n","\n","        decoder_input = tf.concat([decoder_input, [[predicted_id]]], axis=1)\n","\n","    return ' '.join(result)\n","\n","# 테스트\n","test_angles = [16, -29, 22, 5, -18, 27, 20, -7]\n","generated_feedback = generate_feedback(model, tokenizer, test_angles)\n","print(f\"입력 각도: {test_angles}\")\n","print(f\"생성된 피드백: {generated_feedback}\")\n","\n","# 모델 평가\n","test_loss = model.evaluate([X_test, y_test[:, :-1]], y_test[:, 1:])\n","print(f\"Test Loss: {test_loss}\")"],"metadata":{"id":"0-2jn3q5HY0V","executionInfo":{"status":"ok","timestamp":1722318400347,"user_tz":-480,"elapsed":91926,"user":{"displayName":"hy j","userId":"15870501685188288436"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8cd9ffd7-ec0a-4466-9747-16c0b2c1d76f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","60/60 [==============================] - 13s 54ms/step - loss: 3.6250 - val_loss: 2.1597\n","Epoch 2/100\n","60/60 [==============================] - 2s 36ms/step - loss: 2.2270 - val_loss: 1.6613\n","Epoch 3/100\n","60/60 [==============================] - 2s 40ms/step - loss: 1.9526 - val_loss: 1.6828\n","Epoch 4/100\n","60/60 [==============================] - 2s 37ms/step - loss: 1.8772 - val_loss: 1.3628\n","Epoch 5/100\n","60/60 [==============================] - 4s 59ms/step - loss: 1.7446 - val_loss: 1.4587\n","Epoch 6/100\n","60/60 [==============================] - 3s 48ms/step - loss: 1.5776 - val_loss: 1.2721\n","Epoch 7/100\n","60/60 [==============================] - 2s 37ms/step - loss: 1.4979 - val_loss: 1.1860\n","Epoch 8/100\n","60/60 [==============================] - 2s 37ms/step - loss: 1.3328 - val_loss: 1.0216\n","Epoch 9/100\n","60/60 [==============================] - 2s 37ms/step - loss: 1.5192 - val_loss: 1.2462\n","Epoch 10/100\n","60/60 [==============================] - 2s 37ms/step - loss: 1.3249 - val_loss: 0.9979\n","Epoch 11/100\n","60/60 [==============================] - 4s 62ms/step - loss: 1.1430 - val_loss: 0.8484\n","Epoch 12/100\n","60/60 [==============================] - 3s 49ms/step - loss: 1.1330 - val_loss: 0.9370\n","Epoch 13/100\n","60/60 [==============================] - 2s 37ms/step - loss: 1.0509 - val_loss: 0.7774\n","Epoch 14/100\n","60/60 [==============================] - 2s 37ms/step - loss: 1.1728 - val_loss: 0.9913\n","Epoch 15/100\n","60/60 [==============================] - 2s 37ms/step - loss: 1.0707 - val_loss: 0.8191\n","Epoch 16/100\n","60/60 [==============================] - 2s 36ms/step - loss: 1.0172 - val_loss: 0.7566\n","Epoch 17/100\n","60/60 [==============================] - 4s 61ms/step - loss: 0.9209 - val_loss: 0.6900\n","Epoch 18/100\n","60/60 [==============================] - 3s 49ms/step - loss: 0.9576 - val_loss: 0.7881\n","Epoch 19/100\n","60/60 [==============================] - 2s 37ms/step - loss: 1.0217 - val_loss: 1.1446\n","Epoch 20/100\n","60/60 [==============================] - 2s 37ms/step - loss: 1.2761 - val_loss: 0.8973\n","Epoch 21/100\n","60/60 [==============================] - 2s 37ms/step - loss: 1.2287 - val_loss: 0.9130\n","Epoch 22/100\n","60/60 [==============================] - 2s 36ms/step - loss: 1.1370 - val_loss: 0.8581\n","Epoch 23/100\n","60/60 [==============================] - 4s 60ms/step - loss: 1.0990 - val_loss: 0.8971\n","Epoch 24/100\n","60/60 [==============================] - 3s 47ms/step - loss: 1.1577 - val_loss: 1.0351\n","Epoch 25/100\n","60/60 [==============================] - 2s 37ms/step - loss: 1.5690 - val_loss: 1.3476\n","Epoch 26/100\n","60/60 [==============================] - 2s 36ms/step - loss: 2.7796 - val_loss: 4.0806\n","Epoch 27/100\n","60/60 [==============================] - 2s 37ms/step - loss: 4.0964 - val_loss: 4.1139\n","입력 각도: [16, -29, 22, 5, -18, 27, 20, -7]\n","생성된 피드백: \"오른쪽 팔꿈치와 왼쪽 팔꿈치를 더 구부려주세요. 왼쪽 무릎은 더 펴주시고 왼쪽 무릎과 왼쪽 골반을 더 구부려주세요.\"\n","3/3 [==============================] - 1s 22ms/step - loss: 0.6906\n","Test Loss: 0.6905903220176697\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Concatenate\n","from tensorflow.keras.callbacks import EarlyStopping\n","from nltk.translate.bleu_score import sentence_bleu\n","\n","# 데이터 로드\n","df = pd.read_excel(\"/content/drive/MyDrive/자연어 처리 학습 피드백.xlsx\", names=[\"각도차이\", \"피드백\"])\n","angle_differences = df.loc[:, \"각도차이\"].apply(eval).tolist()\n","feedbacks = df.loc[:, \"피드백\"].tolist()\n","\n","# 데이터 증강 (개선)\n","def augment_data(angles, feedbacks):\n","    augmented_angles = []\n","    augmented_feedbacks = []\n","    for angle, feedback in zip(angles, feedbacks):\n","        augmented_angles.append(angle)\n","        augmented_feedbacks.append(feedback)\n","\n","        for _ in range(3):\n","            noisy_angle = [a + np.random.normal(0, 1) for a in angle]  # 노이즈 감소\n","            augmented_angles.append(noisy_angle)\n","            augmented_feedbacks.append(feedback)\n","\n","    return augmented_angles, augmented_feedbacks\n","\n","angle_differences, feedbacks = augment_data(angle_differences, feedbacks)\n","\n","# 데이터 전처리 (개선)\n","def preprocess_data(angles, feedbacks):\n","    # 가장 긴 각도 리스트의 길이 찾기\n","    max_length = max(len(angle) for angle in angles)\n","\n","    # 각도 리스트를 패딩하여 동일한 길이로 만들기\n","    padded_angles = [angle + [0] * (max_length - len(angle)) for angle in angles]\n","\n","    angle_tensor = np.array(padded_angles)\n","    angle_sign = np.sign(angle_tensor)  # 각도의 부호 정보 추출\n","    angle_tensor = np.abs(angle_tensor)  # 절대값 사용\n","\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', lower=True, oov_token=\"<UNK>\")\n","    tokenizer.fit_on_texts(['<start> ' + f.lower() + ' <end>' for f in feedbacks])\n","    feedback_tensor = tokenizer.texts_to_sequences(['<start> ' + f.lower() + ' <end>' for f in feedbacks])\n","    feedback_tensor = tf.keras.preprocessing.sequence.pad_sequences(feedback_tensor, padding='post')\n","\n","    return angle_tensor, angle_sign, feedback_tensor, tokenizer\n","angle_tensor, angle_sign, feedback_tensor, tokenizer = preprocess_data(angle_differences, feedbacks)\n","\n","# 데이터 분할\n","X_angle = angle_tensor\n","X_sign = angle_sign\n","y = feedback_tensor\n","X_angle_train, X_angle_test, X_sign_train, X_sign_test, y_train, y_test = train_test_split(\n","    X_angle, X_sign, y, test_size=0.2, random_state=42)\n","\n","# 모델 정의 (개선)\n","class Seq2SeqModel(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, units):\n","        super(Seq2SeqModel, self).__init__()\n","        self.angle_input = Input(shape=(None,))  # None을 사용하여 가변 길이 입력 허용\n","        self.sign_input = Input(shape=(None,))\n","        self.decoder_input = Input(shape=(None,))\n","\n","        self.angle_dense = Dense(units, activation='relu')\n","        self.sign_dense = Dense(units, activation='relu')\n","        self.concat = Concatenate()\n","\n","        self.embedding = Embedding(vocab_size, embedding_dim)\n","        self.encoder = LSTM(units, return_sequences=True, return_state=True)\n","        self.decoder = LSTM(units, return_sequences=True, return_state=True)\n","        self.dropout = Dropout(0.3)\n","        self.dense = Dense(vocab_size, activation='softmax')\n","\n","    def call(self, inputs, training=False):\n","        angle_input, sign_input, decoder_input = inputs\n","\n","        angle_features = self.angle_dense(angle_input)\n","        sign_features = self.sign_dense(sign_input)\n","        encoder_input = self.concat([angle_features, sign_features])\n","\n","        encoder_output, state_h, state_c = self.encoder(tf.expand_dims(encoder_input, axis=1))\n","\n","        decoder_hidden = self.embedding(decoder_input)\n","        decoder_output, _, _ = self.decoder(decoder_hidden, initial_state=[state_h, state_c])\n","\n","        decoder_output = self.dropout(decoder_output, training=training)\n","        output = self.dense(decoder_output)\n","        return output\n","\n","# 하이퍼파라미터\n","vocab_size = len(tokenizer.word_index) + 1\n","embedding_dim = 256\n","units = 128\n","batch_size = 32\n","epochs = 100\n","\n","# 모델 컴파일\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model = Seq2SeqModel(vocab_size, embedding_dim, units)\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# 모델 학습\n","early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n","history = model.fit([X_angle_train, X_sign_train, y_train[:, :-1]], y_train[:, 1:],\n","                    validation_split=0.2,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    callbacks=[early_stopping])\n","\n","# 피드백 생성 함수 (개선)\n","def generate_feedback(model, tokenizer, angles):\n","    angle_tensor = np.abs(angles)\n","    angle_sign = np.sign(angles)\n","    start_token = tokenizer.word_index['<start>']\n","    end_token = tokenizer.word_index['<end>']\n","\n","    decoder_input = tf.constant([[start_token]])\n","    result = []\n","\n","    for _ in range(50):\n","        predictions = model([np.expand_dims(angle_tensor, 0), np.expand_dims(angle_sign, 0), decoder_input])\n","        predicted_id = tf.argmax(predictions[0, -1, :])\n","        predicted_id = int(predicted_id)\n","\n","        if predicted_id == end_token:\n","            break\n","\n","        if predicted_id in tokenizer.index_word:\n","            result.append(tokenizer.index_word[predicted_id])\n","        else:\n","            result.append(\"<UNK>\")\n","\n","        decoder_input = tf.concat([decoder_input, [[predicted_id]]], axis=1)\n","\n","    return ' '.join(result)\n","\n","# 테스트 및 BLEU 점수 계산\n","def calculate_bleu(reference, candidate):\n","    reference = reference.split()\n","    candidate = candidate.split()\n","    return sentence_bleu([reference], candidate)\n","\n","test_angles = [16, -29, 22, 5, -18, 27, 20, -7]\n","generated_feedback = generate_feedback(model, tokenizer, test_angles)\n","print(f\"입력 각도: {test_angles}\")\n","print(f\"생성된 피드백: {generated_feedback}\")\n","\n","# 모델 평가\n","test_loss, test_accuracy = model.evaluate([X_angle_test, X_sign_test, y_test[:, :-1]], y_test[:, 1:])\n","print(f\"Test Loss: {test_loss}\")\n","print(f\"Test Accuracy: {test_accuracy}\")\n","\n","# BLEU 점수 계산 (전체 테스트 세트에 대해)\n","bleu_scores = []\n","for angles, true_feedback in zip(X_angle_test, y_test):\n","    generated = generate_feedback(model, tokenizer, angles)\n","    true = ' '.join([tokenizer.index_word[idx] for idx in true_feedback if idx != 0 and idx in tokenizer.index_word])\n","    bleu_scores.append(calculate_bleu(true, generated))\n","\n","average_bleu = np.mean(bleu_scores)\n","print(f\"Average BLEU Score: {average_bleu}\")"],"metadata":{"id":"NfibVP2OKzxY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722391485351,"user_tz":-480,"elapsed":85487,"user":{"displayName":"hy j","userId":"15870501685188288436"}},"outputId":"e0b55a82-a819-4d2f-dcbb-83847f47ecfb"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","8/8 [==============================] - 5s 161ms/step - loss: 3.8704 - accuracy: 0.3827 - val_loss: 3.0638 - val_accuracy: 0.4790\n","Epoch 2/100\n","8/8 [==============================] - 0s 43ms/step - loss: 2.6000 - accuracy: 0.4337 - val_loss: 2.1301 - val_accuracy: 0.4704\n","Epoch 3/100\n","8/8 [==============================] - 0s 44ms/step - loss: 2.1868 - accuracy: 0.4617 - val_loss: 1.8903 - val_accuracy: 0.5145\n","Epoch 4/100\n","8/8 [==============================] - 0s 45ms/step - loss: 2.0003 - accuracy: 0.4897 - val_loss: 1.7787 - val_accuracy: 0.5312\n","Epoch 5/100\n","8/8 [==============================] - 0s 44ms/step - loss: 1.8954 - accuracy: 0.5004 - val_loss: 1.6963 - val_accuracy: 0.5317\n","Epoch 6/100\n","8/8 [==============================] - 0s 45ms/step - loss: 1.8134 - accuracy: 0.5145 - val_loss: 1.6347 - val_accuracy: 0.5570\n","Epoch 7/100\n","8/8 [==============================] - 0s 44ms/step - loss: 1.7562 - accuracy: 0.5231 - val_loss: 1.5631 - val_accuracy: 0.5425\n","Epoch 8/100\n","8/8 [==============================] - 0s 45ms/step - loss: 1.6925 - accuracy: 0.5323 - val_loss: 1.5025 - val_accuracy: 0.5892\n","Epoch 9/100\n","8/8 [==============================] - 0s 45ms/step - loss: 1.6320 - accuracy: 0.5528 - val_loss: 1.4458 - val_accuracy: 0.6097\n","Epoch 10/100\n","8/8 [==============================] - 0s 45ms/step - loss: 1.5674 - accuracy: 0.5741 - val_loss: 1.3822 - val_accuracy: 0.6167\n","Epoch 11/100\n","8/8 [==============================] - 0s 44ms/step - loss: 1.5135 - accuracy: 0.5813 - val_loss: 1.3164 - val_accuracy: 0.6527\n","Epoch 12/100\n","8/8 [==============================] - 0s 45ms/step - loss: 1.4430 - accuracy: 0.6054 - val_loss: 1.2406 - val_accuracy: 0.6554\n","Epoch 13/100\n","8/8 [==============================] - 0s 44ms/step - loss: 1.3561 - accuracy: 0.6355 - val_loss: 1.1755 - val_accuracy: 0.7005\n","Epoch 14/100\n","8/8 [==============================] - 0s 45ms/step - loss: 1.2779 - accuracy: 0.6513 - val_loss: 1.0778 - val_accuracy: 0.7161\n","Epoch 15/100\n","8/8 [==============================] - 0s 45ms/step - loss: 1.1904 - accuracy: 0.6733 - val_loss: 0.9969 - val_accuracy: 0.7301\n","Epoch 16/100\n","8/8 [==============================] - 0s 45ms/step - loss: 1.1062 - accuracy: 0.6866 - val_loss: 0.9266 - val_accuracy: 0.7333\n","Epoch 17/100\n","8/8 [==============================] - 0s 46ms/step - loss: 1.0435 - accuracy: 0.7032 - val_loss: 0.8622 - val_accuracy: 0.7554\n","Epoch 18/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.9755 - accuracy: 0.7137 - val_loss: 0.8098 - val_accuracy: 0.7591\n","Epoch 19/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.9244 - accuracy: 0.7274 - val_loss: 0.7644 - val_accuracy: 0.7704\n","Epoch 20/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.8783 - accuracy: 0.7352 - val_loss: 0.7271 - val_accuracy: 0.7839\n","Epoch 21/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.8377 - accuracy: 0.7483 - val_loss: 0.7006 - val_accuracy: 0.7919\n","Epoch 22/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.8033 - accuracy: 0.7567 - val_loss: 0.6673 - val_accuracy: 0.8005\n","Epoch 23/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.7697 - accuracy: 0.7613 - val_loss: 0.6404 - val_accuracy: 0.8134\n","Epoch 24/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.7437 - accuracy: 0.7669 - val_loss: 0.6197 - val_accuracy: 0.8102\n","Epoch 25/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.7124 - accuracy: 0.7765 - val_loss: 0.5930 - val_accuracy: 0.8269\n","Epoch 26/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.6862 - accuracy: 0.7820 - val_loss: 0.5725 - val_accuracy: 0.8414\n","Epoch 27/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.6595 - accuracy: 0.7940 - val_loss: 0.5531 - val_accuracy: 0.8457\n","Epoch 28/100\n","8/8 [==============================] - 0s 51ms/step - loss: 0.6386 - accuracy: 0.7976 - val_loss: 0.5330 - val_accuracy: 0.8414\n","Epoch 29/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.6121 - accuracy: 0.8077 - val_loss: 0.5177 - val_accuracy: 0.8489\n","Epoch 30/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.5967 - accuracy: 0.8179 - val_loss: 0.5029 - val_accuracy: 0.8468\n","Epoch 31/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.5748 - accuracy: 0.8184 - val_loss: 0.4835 - val_accuracy: 0.8511\n","Epoch 32/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.5539 - accuracy: 0.8289 - val_loss: 0.4672 - val_accuracy: 0.8629\n","Epoch 33/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.5386 - accuracy: 0.8333 - val_loss: 0.4598 - val_accuracy: 0.8591\n","Epoch 34/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.5298 - accuracy: 0.8341 - val_loss: 0.4485 - val_accuracy: 0.8586\n","Epoch 35/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.5036 - accuracy: 0.8435 - val_loss: 0.4323 - val_accuracy: 0.8624\n","Epoch 36/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.4901 - accuracy: 0.8496 - val_loss: 0.4180 - val_accuracy: 0.8731\n","Epoch 37/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.4747 - accuracy: 0.8526 - val_loss: 0.4059 - val_accuracy: 0.8758\n","Epoch 38/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.4572 - accuracy: 0.8586 - val_loss: 0.3993 - val_accuracy: 0.8763\n","Epoch 39/100\n","8/8 [==============================] - 0s 43ms/step - loss: 0.4460 - accuracy: 0.8640 - val_loss: 0.3941 - val_accuracy: 0.8780\n","Epoch 40/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.4418 - accuracy: 0.8651 - val_loss: 0.3762 - val_accuracy: 0.8882\n","Epoch 41/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.4243 - accuracy: 0.8667 - val_loss: 0.3648 - val_accuracy: 0.8914\n","Epoch 42/100\n","8/8 [==============================] - 0s 46ms/step - loss: 0.4119 - accuracy: 0.8743 - val_loss: 0.3555 - val_accuracy: 0.8962\n","Epoch 43/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.3984 - accuracy: 0.8781 - val_loss: 0.3587 - val_accuracy: 0.8844\n","Epoch 44/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.4042 - accuracy: 0.8742 - val_loss: 0.3563 - val_accuracy: 0.8823\n","Epoch 45/100\n","8/8 [==============================] - 0s 46ms/step - loss: 0.3927 - accuracy: 0.8762 - val_loss: 0.3399 - val_accuracy: 0.8935\n","Epoch 46/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.3769 - accuracy: 0.8836 - val_loss: 0.3367 - val_accuracy: 0.8957\n","Epoch 47/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.3665 - accuracy: 0.8891 - val_loss: 0.3270 - val_accuracy: 0.8919\n","Epoch 48/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.3476 - accuracy: 0.8993 - val_loss: 0.3101 - val_accuracy: 0.9086\n","Epoch 49/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.3398 - accuracy: 0.8948 - val_loss: 0.3137 - val_accuracy: 0.9032\n","Epoch 50/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.3328 - accuracy: 0.8992 - val_loss: 0.2984 - val_accuracy: 0.9075\n","Epoch 51/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.3274 - accuracy: 0.8977 - val_loss: 0.2924 - val_accuracy: 0.9140\n","Epoch 52/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.3112 - accuracy: 0.9099 - val_loss: 0.2841 - val_accuracy: 0.9134\n","Epoch 53/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.3077 - accuracy: 0.9073 - val_loss: 0.2772 - val_accuracy: 0.9172\n","Epoch 54/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2989 - accuracy: 0.9082 - val_loss: 0.2732 - val_accuracy: 0.9172\n","Epoch 55/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2958 - accuracy: 0.9152 - val_loss: 0.2679 - val_accuracy: 0.9161\n","Epoch 56/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2906 - accuracy: 0.9149 - val_loss: 0.2584 - val_accuracy: 0.9237\n","Epoch 57/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.2816 - accuracy: 0.9163 - val_loss: 0.2692 - val_accuracy: 0.9161\n","Epoch 58/100\n","8/8 [==============================] - 0s 46ms/step - loss: 0.2766 - accuracy: 0.9175 - val_loss: 0.2549 - val_accuracy: 0.9226\n","Epoch 59/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.2663 - accuracy: 0.9223 - val_loss: 0.2480 - val_accuracy: 0.9280\n","Epoch 60/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2596 - accuracy: 0.9243 - val_loss: 0.2436 - val_accuracy: 0.9247\n","Epoch 61/100\n","8/8 [==============================] - 0s 43ms/step - loss: 0.2548 - accuracy: 0.9282 - val_loss: 0.2324 - val_accuracy: 0.9355\n","Epoch 62/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.2423 - accuracy: 0.9352 - val_loss: 0.2228 - val_accuracy: 0.9382\n","Epoch 63/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2356 - accuracy: 0.9329 - val_loss: 0.2217 - val_accuracy: 0.9430\n","Epoch 64/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.2266 - accuracy: 0.9380 - val_loss: 0.2108 - val_accuracy: 0.9425\n","Epoch 65/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.2203 - accuracy: 0.9418 - val_loss: 0.2043 - val_accuracy: 0.9441\n","Epoch 66/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.2139 - accuracy: 0.9421 - val_loss: 0.2005 - val_accuracy: 0.9468\n","Epoch 67/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.2119 - accuracy: 0.9431 - val_loss: 0.2038 - val_accuracy: 0.9435\n","Epoch 68/100\n","8/8 [==============================] - 0s 43ms/step - loss: 0.2154 - accuracy: 0.9379 - val_loss: 0.2013 - val_accuracy: 0.9441\n","Epoch 69/100\n","8/8 [==============================] - 0s 43ms/step - loss: 0.2218 - accuracy: 0.9374 - val_loss: 0.2070 - val_accuracy: 0.9376\n","Epoch 70/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.2069 - accuracy: 0.9406 - val_loss: 0.1970 - val_accuracy: 0.9478\n","Epoch 71/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.2113 - accuracy: 0.9406 - val_loss: 0.1914 - val_accuracy: 0.9473\n","Epoch 72/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1994 - accuracy: 0.9442 - val_loss: 0.1838 - val_accuracy: 0.9532\n","Epoch 73/100\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1877 - accuracy: 0.9503 - val_loss: 0.1739 - val_accuracy: 0.9575\n","Epoch 74/100\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1819 - accuracy: 0.9542 - val_loss: 0.1661 - val_accuracy: 0.9608\n","Epoch 75/100\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1707 - accuracy: 0.9608 - val_loss: 0.1715 - val_accuracy: 0.9522\n","Epoch 76/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1787 - accuracy: 0.9516 - val_loss: 0.1558 - val_accuracy: 0.9629\n","Epoch 77/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1656 - accuracy: 0.9602 - val_loss: 0.1607 - val_accuracy: 0.9629\n","Epoch 78/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1714 - accuracy: 0.9551 - val_loss: 0.1551 - val_accuracy: 0.9661\n","Epoch 79/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1687 - accuracy: 0.9566 - val_loss: 0.1656 - val_accuracy: 0.9527\n","Epoch 80/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1624 - accuracy: 0.9586 - val_loss: 0.1428 - val_accuracy: 0.9715\n","Epoch 81/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1490 - accuracy: 0.9675 - val_loss: 0.1415 - val_accuracy: 0.9720\n","Epoch 82/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1442 - accuracy: 0.9672 - val_loss: 0.1336 - val_accuracy: 0.9726\n","Epoch 83/100\n","8/8 [==============================] - 0s 46ms/step - loss: 0.1364 - accuracy: 0.9704 - val_loss: 0.1307 - val_accuracy: 0.9715\n","Epoch 84/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1359 - accuracy: 0.9702 - val_loss: 0.1326 - val_accuracy: 0.9737\n","Epoch 85/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1341 - accuracy: 0.9680 - val_loss: 0.1324 - val_accuracy: 0.9688\n","Epoch 86/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1346 - accuracy: 0.9691 - val_loss: 0.1309 - val_accuracy: 0.9694\n","Epoch 87/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1395 - accuracy: 0.9642 - val_loss: 0.1229 - val_accuracy: 0.9747\n","Epoch 88/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1299 - accuracy: 0.9704 - val_loss: 0.1180 - val_accuracy: 0.9812\n","Epoch 89/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1244 - accuracy: 0.9707 - val_loss: 0.1151 - val_accuracy: 0.9780\n","Epoch 90/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1155 - accuracy: 0.9789 - val_loss: 0.1125 - val_accuracy: 0.9790\n","Epoch 91/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1133 - accuracy: 0.9773 - val_loss: 0.1035 - val_accuracy: 0.9844\n","Epoch 92/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1084 - accuracy: 0.9805 - val_loss: 0.1048 - val_accuracy: 0.9806\n","Epoch 93/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1044 - accuracy: 0.9801 - val_loss: 0.0988 - val_accuracy: 0.9839\n","Epoch 94/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1021 - accuracy: 0.9820 - val_loss: 0.0981 - val_accuracy: 0.9844\n","Epoch 95/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1010 - accuracy: 0.9829 - val_loss: 0.0953 - val_accuracy: 0.9892\n","Epoch 96/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.0994 - accuracy: 0.9796 - val_loss: 0.1030 - val_accuracy: 0.9806\n","Epoch 97/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1047 - accuracy: 0.9766 - val_loss: 0.0997 - val_accuracy: 0.9812\n","Epoch 98/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1001 - accuracy: 0.9815 - val_loss: 0.0989 - val_accuracy: 0.9828\n","Epoch 99/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.0980 - accuracy: 0.9800 - val_loss: 0.0899 - val_accuracy: 0.9860\n","Epoch 100/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.0937 - accuracy: 0.9833 - val_loss: 0.0958 - val_accuracy: 0.9839\n","입력 각도: [16, -29, 22, 5, -18, 27, 20, -7]\n","생성된 피드백: \"오른쪽 팔꿈치와 오른쪽 무릎을 더 구부려주시고, 왼쪽 팔꿈치는 더 펴주세요.오른쪽 발목을 더 펴주시고 왼쪽 발목과 오른쪽 골반은 더 구부려주세요.\"\n","3/3 [==============================] - 0s 13ms/step - loss: 0.0814 - accuracy: 0.9873\n","Test Loss: 0.08135408908128738\n","Test Accuracy: 0.9872665405273438\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["Average BLEU Score: 0.3484502290101446\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","# 콜백 정의\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',\n","    patience=10,\n","    restore_best_weights=True,\n","    verbose=1\n",")\n","\n","model_checkpoint = ModelCheckpoint(\n","    'best_model.h5',\n","    monitor='val_loss',\n","    save_best_only=True,\n","    save_weights_only=False,\n","    mode='min',\n","    verbose=1\n",")\n","\n","# 모델 학습\n","history = model.fit(\n","    [X_angle_train, X_sign_train, y_train[:, :-1]], y_train[:, 1:],\n","    validation_split=0.2,\n","    batch_size=batch_size,\n","    epochs=epochs,\n","    callbacks=[early_stopping, model_checkpoint]\n",")"],"metadata":{"id":"E56jjULuLrYw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout, Concatenate\n","from nltk.translate.bleu_score import sentence_bleu\n","import os\n","from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback, EarlyStopping\n","from tensorflow.keras.callbacks import Callback\n","\n","# 데이터 로드\n","df = pd.read_excel(\"/content/drive/MyDrive/자연어 처리 학습 피드백.xlsx\", names=[\"각도차이\", \"피드백\"])\n","angle_differences = df.loc[:, \"각도차이\"].apply(eval).tolist()\n","feedbacks = df.loc[:, \"피드백\"].tolist()\n","\n","# 데이터 증강 (개선)\n","def augment_data(angles, feedbacks):\n","    augmented_angles = []\n","    augmented_feedbacks = []\n","    for angle, feedback in zip(angles, feedbacks):\n","        augmented_angles.append(angle)\n","        augmented_feedbacks.append(feedback)\n","\n","        for _ in range(3):\n","            noisy_angle = [a + np.random.normal(0, 1) for a in angle]  # 노이즈 감소\n","            augmented_angles.append(noisy_angle)\n","            augmented_feedbacks.append(feedback)\n","\n","    return augmented_angles, augmented_feedbacks\n","\n","angle_differences, feedbacks = augment_data(angle_differences, feedbacks)\n","\n","# 데이터 전처리 (개선)\n","def preprocess_data(angles, feedbacks):\n","    # 가장 긴 각도 리스트의 길이 찾기\n","    max_length = max(len(angle) for angle in angles)\n","\n","    # 각도 리스트를 패딩하여 동일한 길이로 만들기\n","    padded_angles = [angle + [0] * (max_length - len(angle)) for angle in angles]\n","\n","    angle_tensor = np.array(padded_angles)\n","    angle_sign = np.sign(angle_tensor)  # 각도의 부호 정보 추출\n","    angle_tensor = np.abs(angle_tensor)  # 절대값 사용\n","\n","    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', lower=True, oov_token=\"<UNK>\")\n","    tokenizer.fit_on_texts(['<start> ' + f.lower() + ' <end>' for f in feedbacks])\n","    feedback_tensor = tokenizer.texts_to_sequences(['<start> ' + f.lower() + ' <end>' for f in feedbacks])\n","    feedback_tensor = tf.keras.preprocessing.sequence.pad_sequences(feedback_tensor, padding='post')\n","\n","    return angle_tensor, angle_sign, feedback_tensor, tokenizer\n","angle_tensor, angle_sign, feedback_tensor, tokenizer = preprocess_data(angle_differences, feedbacks)\n","\n","# 데이터 분할\n","X_angle = angle_tensor\n","X_sign = angle_sign\n","y = feedback_tensor\n","X_angle_train, X_angle_test, X_sign_train, X_sign_test, y_train, y_test = train_test_split(\n","    X_angle, X_sign, y, test_size=0.2, random_state=42)\n","\n","# 모델 정의 (개선)\n","class Seq2SeqModel(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, units):\n","        super(Seq2SeqModel, self).__init__()\n","        self.angle_input = Input(shape=(None,))  # None을 사용하여 가변 길이 입력 허용\n","        self.sign_input = Input(shape=(None,))\n","        self.decoder_input = Input(shape=(None,))\n","\n","        self.angle_dense = Dense(units, activation='relu')\n","        self.sign_dense = Dense(units, activation='relu')\n","        self.concat = Concatenate()\n","\n","        self.embedding = Embedding(vocab_size, embedding_dim)\n","        self.encoder = LSTM(units, return_sequences=True, return_state=True)\n","        self.decoder = LSTM(units, return_sequences=True, return_state=True)\n","        self.dropout = Dropout(0.3)\n","        self.dense = Dense(vocab_size, activation='softmax')\n","\n","    def call(self, inputs, training=False):\n","        angle_input, sign_input, decoder_input = inputs\n","\n","        angle_features = self.angle_dense(angle_input)\n","        sign_features = self.sign_dense(sign_input)\n","        encoder_input = self.concat([angle_features, sign_features])\n","\n","        encoder_output, state_h, state_c = self.encoder(tf.expand_dims(encoder_input, axis=1))\n","\n","        decoder_hidden = self.embedding(decoder_input)\n","        decoder_output, _, _ = self.decoder(decoder_hidden, initial_state=[state_h, state_c])\n","\n","        decoder_output = self.dropout(decoder_output, training=training)\n","        output = self.dense(decoder_output)\n","        return output\n","\n","# 하이퍼파라미터\n","vocab_size = len(tokenizer.word_index) + 1\n","embedding_dim = 256\n","units = 128\n","batch_size = 32\n","epochs = 100\n","\n","# 모델 컴파일\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","model = Seq2SeqModel(vocab_size, embedding_dim, units)\n","model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","\n","class EfficientModelCheckpoint(Callback):\n","    def __init__(self, patience=10):\n","        super().__init__()\n","        self.patience = patience\n","        self.best_val_loss = float('inf')\n","        self.best_weights = None\n","        self.wait = 0\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        current_val_loss = logs.get('val_loss')\n","        if current_val_loss < self.best_val_loss:\n","            self.best_val_loss = current_val_loss\n","            self.best_weights = self.model.get_weights()\n","            self.wait = 0\n","            print(f\"\\nEpoch {epoch+1}: 새로운 최상의 모델 발견 (val_loss: {current_val_loss:.4f})\")\n","        else:\n","            self.wait += 1\n","            if self.wait >= self.patience:\n","                self.model.stop_training = True\n","                print(f\"\\n{self.patience} 에포크 동안 개선이 없어 학습을 종료합니다.\")\n","                print(f\"최상의 val_loss: {self.best_val_loss:.4f}\")\n","                self.model.set_weights(self.best_weights)\n","\n","# 콜백 인스턴스 생성\n","efficient_checkpoint = EfficientModelCheckpoint(patience=10)\n","\n","# 모델 학습\n","history = model.fit(\n","    [X_angle_train, X_sign_train, y_train[:, :-1]], y_train[:, 1:],\n","    validation_split=0.2,\n","    batch_size=batch_size,\n","    epochs=epochs,\n","    callbacks=[efficient_checkpoint]\n",")\n","\n","# 학습 후 최상의 모델 저장\n","model.save('best_model', save_format='tf')\n","\n","# 피드백 생성 함수 (개선)\n","def generate_feedback(model, tokenizer, angles):\n","    angle_tensor = np.abs(angles)\n","    angle_sign = np.sign(angles)\n","    start_token = tokenizer.word_index['<start>']\n","    end_token = tokenizer.word_index['<end>']\n","\n","    decoder_input = tf.constant([[start_token]])\n","    result = []\n","\n","    for _ in range(50):\n","        predictions = model([np.expand_dims(angle_tensor, 0), np.expand_dims(angle_sign, 0), decoder_input])\n","        predicted_id = tf.argmax(predictions[0, -1, :])\n","        predicted_id = int(predicted_id)\n","\n","        if predicted_id == end_token:\n","            break\n","\n","        if predicted_id in tokenizer.index_word:\n","            result.append(tokenizer.index_word[predicted_id])\n","        else:\n","            result.append(\"<UNK>\")\n","\n","        decoder_input = tf.concat([decoder_input, [[predicted_id]]], axis=1)\n","\n","    return ' '.join(result)\n","\n","# 테스트 및 BLEU 점수 계산\n","def calculate_bleu(reference, candidate):\n","    reference = reference.split()\n","    candidate = candidate.split()\n","    return sentence_bleu([reference], candidate)\n","\n","test_angles = [16, -29, 22, 5, -18, 27, 20, -7]\n","generated_feedback = generate_feedback(model, tokenizer, test_angles)\n","print(f\"입력 각도: {test_angles}\")\n","print(f\"생성된 피드백: {generated_feedback}\")\n","\n","# 모델 평가\n","test_loss, test_accuracy = model.evaluate([X_angle_test, X_sign_test, y_test[:, :-1]], y_test[:, 1:])\n","print(f\"Test Loss: {test_loss}\")\n","print(f\"Test Accuracy: {test_accuracy}\")\n","\n","# BLEU 점수 계산 (전체 테스트 세트에 대해)\n","bleu_scores = []\n","for angles, true_feedback in zip(X_angle_test, y_test):\n","    generated = generate_feedback(model, tokenizer, angles)\n","    true = ' '.join([tokenizer.index_word[idx] for idx in true_feedback if idx != 0 and idx in tokenizer.index_word])\n","    bleu_scores.append(calculate_bleu(true, generated))\n","\n","average_bleu = np.mean(bleu_scores)\n","print(f\"Average BLEU Score: {average_bleu}\")"],"metadata":{"id":"Hn_pSXFCL7M2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722392111408,"user_tz":-480,"elapsed":90630,"user":{"displayName":"hy j","userId":"15870501685188288436"}},"outputId":"9d4e244f-dbc9-446e-a6ff-9d99464a3fe5"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","7/8 [=========================>....] - ETA: 0s - loss: 3.9554 - accuracy: 0.3603\n","Epoch 1: 새로운 최상의 모델 발견 (val_loss: 3.3027)\n","8/8 [==============================] - 5s 155ms/step - loss: 3.9262 - accuracy: 0.3692 - val_loss: 3.3027 - val_accuracy: 0.4817\n","Epoch 2/100\n","7/8 [=========================>....] - ETA: 0s - loss: 2.8266 - accuracy: 0.4293\n","Epoch 2: 새로운 최상의 모델 발견 (val_loss: 2.2529)\n","8/8 [==============================] - 0s 43ms/step - loss: 2.7830 - accuracy: 0.4349 - val_loss: 2.2529 - val_accuracy: 0.4699\n","Epoch 3/100\n","7/8 [=========================>....] - ETA: 0s - loss: 2.2983 - accuracy: 0.4587\n","Epoch 3: 새로운 최상의 모델 발견 (val_loss: 1.9423)\n","8/8 [==============================] - 0s 43ms/step - loss: 2.2756 - accuracy: 0.4621 - val_loss: 1.9423 - val_accuracy: 0.4984\n","Epoch 4/100\n","7/8 [=========================>....] - ETA: 0s - loss: 2.0443 - accuracy: 0.4846\n","Epoch 4: 새로운 최상의 모델 발견 (val_loss: 1.8048)\n","8/8 [==============================] - 0s 45ms/step - loss: 2.0373 - accuracy: 0.4837 - val_loss: 1.8048 - val_accuracy: 0.5301\n","Epoch 5/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.9243 - accuracy: 0.5003\n","Epoch 5: 새로운 최상의 모델 발견 (val_loss: 1.7104)\n","8/8 [==============================] - 0s 43ms/step - loss: 1.9125 - accuracy: 0.5030 - val_loss: 1.7104 - val_accuracy: 0.5371\n","Epoch 6/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.8515 - accuracy: 0.5014\n","Epoch 6: 새로운 최상의 모델 발견 (val_loss: 1.6382)\n","8/8 [==============================] - 0s 43ms/step - loss: 1.8350 - accuracy: 0.5075 - val_loss: 1.6382 - val_accuracy: 0.5344\n","Epoch 7/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.7507 - accuracy: 0.5256\n","Epoch 7: 새로운 최상의 모델 발견 (val_loss: 1.5805)\n","8/8 [==============================] - 0s 44ms/step - loss: 1.7638 - accuracy: 0.5200 - val_loss: 1.5805 - val_accuracy: 0.5651\n","Epoch 8/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.7246 - accuracy: 0.5304\n","Epoch 8: 새로운 최상의 모델 발견 (val_loss: 1.5295)\n","8/8 [==============================] - 0s 43ms/step - loss: 1.7153 - accuracy: 0.5306 - val_loss: 1.5295 - val_accuracy: 0.5785\n","Epoch 9/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.6631 - accuracy: 0.5444\n","Epoch 9: 새로운 최상의 모델 발견 (val_loss: 1.4742)\n","8/8 [==============================] - 0s 43ms/step - loss: 1.6601 - accuracy: 0.5456 - val_loss: 1.4742 - val_accuracy: 0.5667\n","Epoch 10/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.6027 - accuracy: 0.5573\n","Epoch 10: 새로운 최상의 모델 발견 (val_loss: 1.4126)\n","8/8 [==============================] - 0s 44ms/step - loss: 1.6007 - accuracy: 0.5579 - val_loss: 1.4126 - val_accuracy: 0.6145\n","Epoch 11/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.5427 - accuracy: 0.5736\n","Epoch 11: 새로운 최상의 모델 발견 (val_loss: 1.3721)\n","8/8 [==============================] - 0s 41ms/step - loss: 1.5449 - accuracy: 0.5735 - val_loss: 1.3721 - val_accuracy: 0.6441\n","Epoch 12/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.4913 - accuracy: 0.5933\n","Epoch 12: 새로운 최상의 모델 발견 (val_loss: 1.2917)\n","8/8 [==============================] - 0s 43ms/step - loss: 1.4864 - accuracy: 0.5941 - val_loss: 1.2917 - val_accuracy: 0.6527\n","Epoch 13/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.4040 - accuracy: 0.6123\n","Epoch 13: 새로운 최상의 모델 발견 (val_loss: 1.2166)\n","8/8 [==============================] - 0s 44ms/step - loss: 1.4198 - accuracy: 0.6079 - val_loss: 1.2166 - val_accuracy: 0.6704\n","Epoch 14/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.3310 - accuracy: 0.6368\n","Epoch 14: 새로운 최상의 모델 발견 (val_loss: 1.1473)\n","8/8 [==============================] - 0s 43ms/step - loss: 1.3434 - accuracy: 0.6328 - val_loss: 1.1473 - val_accuracy: 0.6962\n","Epoch 15/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.2691 - accuracy: 0.6519\n","Epoch 15: 새로운 최상의 모델 발견 (val_loss: 1.0608)\n","8/8 [==============================] - 0s 44ms/step - loss: 1.2622 - accuracy: 0.6548 - val_loss: 1.0608 - val_accuracy: 0.7145\n","Epoch 16/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.1785 - accuracy: 0.6708\n","Epoch 16: 새로운 최상의 모델 발견 (val_loss: 0.9819)\n","8/8 [==============================] - 0s 46ms/step - loss: 1.1799 - accuracy: 0.6715 - val_loss: 0.9819 - val_accuracy: 0.7194\n","Epoch 17/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.1002 - accuracy: 0.6858\n","Epoch 17: 새로운 최상의 모델 발견 (val_loss: 0.9107)\n","8/8 [==============================] - 0s 45ms/step - loss: 1.0950 - accuracy: 0.6871 - val_loss: 0.9107 - val_accuracy: 0.7376\n","Epoch 18/100\n","7/8 [=========================>....] - ETA: 0s - loss: 1.0327 - accuracy: 0.7095\n","Epoch 18: 새로운 최상의 모델 발견 (val_loss: 0.8459)\n","8/8 [==============================] - 0s 45ms/step - loss: 1.0258 - accuracy: 0.7101 - val_loss: 0.8459 - val_accuracy: 0.7559\n","Epoch 19/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.9716 - accuracy: 0.7176\n","Epoch 19: 새로운 최상의 모델 발견 (val_loss: 0.8041)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.9657 - accuracy: 0.7187 - val_loss: 0.8041 - val_accuracy: 0.7677\n","Epoch 20/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.9162 - accuracy: 0.7340\n","Epoch 20: 새로운 최상의 모델 발견 (val_loss: 0.7544)\n","8/8 [==============================] - 0s 46ms/step - loss: 0.9200 - accuracy: 0.7324 - val_loss: 0.7544 - val_accuracy: 0.7823\n","Epoch 21/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.8575 - accuracy: 0.7418\n","Epoch 21: 새로운 최상의 모델 발견 (val_loss: 0.7167)\n","8/8 [==============================] - 0s 46ms/step - loss: 0.8694 - accuracy: 0.7382 - val_loss: 0.7167 - val_accuracy: 0.7876\n","Epoch 22/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.8212 - accuracy: 0.7496\n","Epoch 22: 새로운 최상의 모델 발견 (val_loss: 0.6848)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.8227 - accuracy: 0.7492 - val_loss: 0.6848 - val_accuracy: 0.8011\n","Epoch 23/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7969 - accuracy: 0.7560\n","Epoch 23: 새로운 최상의 모델 발견 (val_loss: 0.6567)\n","8/8 [==============================] - 0s 46ms/step - loss: 0.7879 - accuracy: 0.7585 - val_loss: 0.6567 - val_accuracy: 0.8102\n","Epoch 24/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7458 - accuracy: 0.7713\n","Epoch 24: 새로운 최상의 모델 발견 (val_loss: 0.6280)\n","8/8 [==============================] - 0s 46ms/step - loss: 0.7504 - accuracy: 0.7675 - val_loss: 0.6280 - val_accuracy: 0.8172\n","Epoch 25/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.7238 - accuracy: 0.7746\n","Epoch 25: 새로운 최상의 모델 발견 (val_loss: 0.6106)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.7209 - accuracy: 0.7743 - val_loss: 0.6106 - val_accuracy: 0.8177\n","Epoch 26/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6914 - accuracy: 0.7831\n","Epoch 26: 새로운 최상의 모델 발견 (val_loss: 0.5857)\n","8/8 [==============================] - 0s 46ms/step - loss: 0.6933 - accuracy: 0.7823 - val_loss: 0.5857 - val_accuracy: 0.8237\n","Epoch 27/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6718 - accuracy: 0.7892\n","Epoch 27: 새로운 최상의 모델 발견 (val_loss: 0.5667)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.6693 - accuracy: 0.7888 - val_loss: 0.5667 - val_accuracy: 0.8323\n","Epoch 28/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6490 - accuracy: 0.7969\n","Epoch 28: 새로운 최상의 모델 발견 (val_loss: 0.5544)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.6467 - accuracy: 0.7977 - val_loss: 0.5544 - val_accuracy: 0.8328\n","Epoch 29/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6174 - accuracy: 0.8046\n","Epoch 29: 새로운 최상의 모델 발견 (val_loss: 0.5325)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.6240 - accuracy: 0.8023 - val_loss: 0.5325 - val_accuracy: 0.8403\n","Epoch 30/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.6020 - accuracy: 0.8093\n","Epoch 30: 새로운 최상의 모델 발견 (val_loss: 0.5176)\n","8/8 [==============================] - 0s 44ms/step - loss: 0.6012 - accuracy: 0.8091 - val_loss: 0.5176 - val_accuracy: 0.8371\n","Epoch 31/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5856 - accuracy: 0.8171\n","Epoch 31: 새로운 최상의 모델 발견 (val_loss: 0.4991)\n","8/8 [==============================] - 0s 44ms/step - loss: 0.5853 - accuracy: 0.8148 - val_loss: 0.4991 - val_accuracy: 0.8446\n","Epoch 32/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5743 - accuracy: 0.8183\n","Epoch 32: 새로운 최상의 모델 발견 (val_loss: 0.4821)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.5658 - accuracy: 0.8208 - val_loss: 0.4821 - val_accuracy: 0.8532\n","Epoch 33/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5536 - accuracy: 0.8266\n","Epoch 33: 새로운 최상의 모델 발견 (val_loss: 0.4806)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.5557 - accuracy: 0.8247 - val_loss: 0.4806 - val_accuracy: 0.8473\n","Epoch 34/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5388 - accuracy: 0.8299\n","Epoch 34: 새로운 최상의 모델 발견 (val_loss: 0.4700)\n","8/8 [==============================] - 0s 44ms/step - loss: 0.5423 - accuracy: 0.8280 - val_loss: 0.4700 - val_accuracy: 0.8516\n","Epoch 35/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.5250 - accuracy: 0.8358\n","Epoch 35: 새로운 최상의 모델 발견 (val_loss: 0.4506)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.5221 - accuracy: 0.8371 - val_loss: 0.4506 - val_accuracy: 0.8575\n","Epoch 36/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4982 - accuracy: 0.8397\n","Epoch 36: 새로운 최상의 모델 발견 (val_loss: 0.4376)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.4995 - accuracy: 0.8399 - val_loss: 0.4376 - val_accuracy: 0.8591\n","Epoch 37/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4905 - accuracy: 0.8442\n","Epoch 37: 새로운 최상의 모델 발견 (val_loss: 0.4217)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.4868 - accuracy: 0.8468 - val_loss: 0.4217 - val_accuracy: 0.8651\n","Epoch 38/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4745 - accuracy: 0.8550\n","Epoch 38: 새로운 최상의 모델 발견 (val_loss: 0.4064)\n","8/8 [==============================] - 0s 44ms/step - loss: 0.4744 - accuracy: 0.8554 - val_loss: 0.4064 - val_accuracy: 0.8763\n","Epoch 39/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4621 - accuracy: 0.8564\n","Epoch 39: 새로운 최상의 모델 발견 (val_loss: 0.4005)\n","8/8 [==============================] - 0s 42ms/step - loss: 0.4620 - accuracy: 0.8551 - val_loss: 0.4005 - val_accuracy: 0.8769\n","Epoch 40/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4407 - accuracy: 0.8602\n","Epoch 40: 새로운 최상의 모델 발견 (val_loss: 0.3899)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.4395 - accuracy: 0.8601 - val_loss: 0.3899 - val_accuracy: 0.8790\n","Epoch 41/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4339 - accuracy: 0.8630\n","Epoch 41: 새로운 최상의 모델 발견 (val_loss: 0.3828)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.4325 - accuracy: 0.8629 - val_loss: 0.3828 - val_accuracy: 0.8801\n","Epoch 42/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4203 - accuracy: 0.8726\n","Epoch 42: 새로운 최상의 모델 발견 (val_loss: 0.3658)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.4188 - accuracy: 0.8728 - val_loss: 0.3658 - val_accuracy: 0.8844\n","Epoch 43/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.4062 - accuracy: 0.8773\n","Epoch 43: 새로운 최상의 모델 발견 (val_loss: 0.3538)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.4047 - accuracy: 0.8777 - val_loss: 0.3538 - val_accuracy: 0.8882\n","Epoch 44/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3911 - accuracy: 0.8831\n","Epoch 44: 새로운 최상의 모델 발견 (val_loss: 0.3531)\n","8/8 [==============================] - 0s 46ms/step - loss: 0.3907 - accuracy: 0.8827 - val_loss: 0.3531 - val_accuracy: 0.8919\n","Epoch 45/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3823 - accuracy: 0.8846\n","Epoch 45: 새로운 최상의 모델 발견 (val_loss: 0.3362)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.3823 - accuracy: 0.8851 - val_loss: 0.3362 - val_accuracy: 0.8930\n","Epoch 46/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3705 - accuracy: 0.8908\n","Epoch 46: 새로운 최상의 모델 발견 (val_loss: 0.3262)\n","8/8 [==============================] - 0s 46ms/step - loss: 0.3704 - accuracy: 0.8919 - val_loss: 0.3262 - val_accuracy: 0.8941\n","Epoch 47/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3563 - accuracy: 0.8933\n","Epoch 47: 새로운 최상의 모델 발견 (val_loss: 0.3197)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.3563 - accuracy: 0.8927 - val_loss: 0.3197 - val_accuracy: 0.9054\n","Epoch 48/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3507 - accuracy: 0.8966\n","Epoch 48: 새로운 최상의 모델 발견 (val_loss: 0.3142)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.3509 - accuracy: 0.8969 - val_loss: 0.3142 - val_accuracy: 0.9054\n","Epoch 49/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.3489 - accuracy: 0.8948 - val_loss: 0.3246 - val_accuracy: 0.8946\n","Epoch 50/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3372 - accuracy: 0.8993\n","Epoch 50: 새로운 최상의 모델 발견 (val_loss: 0.2918)\n","8/8 [==============================] - 0s 46ms/step - loss: 0.3338 - accuracy: 0.9005 - val_loss: 0.2918 - val_accuracy: 0.9118\n","Epoch 51/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.3238 - accuracy: 0.9017 - val_loss: 0.3021 - val_accuracy: 0.9097\n","Epoch 52/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3147 - accuracy: 0.9087\n","Epoch 52: 새로운 최상의 모델 발견 (val_loss: 0.2817)\n","8/8 [==============================] - 0s 44ms/step - loss: 0.3145 - accuracy: 0.9093 - val_loss: 0.2817 - val_accuracy: 0.9140\n","Epoch 53/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3060 - accuracy: 0.9106\n","Epoch 53: 새로운 최상의 모델 발견 (val_loss: 0.2755)\n","8/8 [==============================] - 0s 46ms/step - loss: 0.3059 - accuracy: 0.9102 - val_loss: 0.2755 - val_accuracy: 0.9167\n","Epoch 54/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.3031 - accuracy: 0.9086\n","Epoch 54: 새로운 최상의 모델 발견 (val_loss: 0.2728)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.3010 - accuracy: 0.9098 - val_loss: 0.2728 - val_accuracy: 0.9151\n","Epoch 55/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2886 - accuracy: 0.9150\n","Epoch 55: 새로운 최상의 모델 발견 (val_loss: 0.2621)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2878 - accuracy: 0.9157 - val_loss: 0.2621 - val_accuracy: 0.9220\n","Epoch 56/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.2823 - accuracy: 0.9214 - val_loss: 0.2725 - val_accuracy: 0.9188\n","Epoch 57/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2740 - accuracy: 0.9237\n","Epoch 57: 새로운 최상의 모델 발견 (val_loss: 0.2528)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2781 - accuracy: 0.9222 - val_loss: 0.2528 - val_accuracy: 0.9199\n","Epoch 58/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2665 - accuracy: 0.9276\n","Epoch 58: 새로운 최상의 모델 발견 (val_loss: 0.2483)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2640 - accuracy: 0.9276 - val_loss: 0.2483 - val_accuracy: 0.9280\n","Epoch 59/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2603 - accuracy: 0.9266\n","Epoch 59: 새로운 최상의 모델 발견 (val_loss: 0.2402)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2608 - accuracy: 0.9265 - val_loss: 0.2402 - val_accuracy: 0.9317\n","Epoch 60/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2553 - accuracy: 0.9248\n","Epoch 60: 새로운 최상의 모델 발견 (val_loss: 0.2360)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2548 - accuracy: 0.9253 - val_loss: 0.2360 - val_accuracy: 0.9339\n","Epoch 61/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2416 - accuracy: 0.9368\n","Epoch 61: 새로운 최상의 모델 발견 (val_loss: 0.2309)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2426 - accuracy: 0.9363 - val_loss: 0.2309 - val_accuracy: 0.9317\n","Epoch 62/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2405 - accuracy: 0.9338\n","Epoch 62: 새로운 최상의 모델 발견 (val_loss: 0.2256)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2403 - accuracy: 0.9340 - val_loss: 0.2256 - val_accuracy: 0.9371\n","Epoch 63/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2335 - accuracy: 0.9376\n","Epoch 63: 새로운 최상의 모델 발견 (val_loss: 0.2216)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2346 - accuracy: 0.9368 - val_loss: 0.2216 - val_accuracy: 0.9371\n","Epoch 64/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2245 - accuracy: 0.9387\n","Epoch 64: 새로운 최상의 모델 발견 (val_loss: 0.2043)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2258 - accuracy: 0.9379 - val_loss: 0.2043 - val_accuracy: 0.9457\n","Epoch 65/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2213 - accuracy: 0.9431\n","Epoch 65: 새로운 최상의 모델 발견 (val_loss: 0.2035)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2207 - accuracy: 0.9433 - val_loss: 0.2035 - val_accuracy: 0.9441\n","Epoch 66/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2081 - accuracy: 0.9464\n","Epoch 66: 새로운 최상의 모델 발견 (val_loss: 0.1985)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2099 - accuracy: 0.9457 - val_loss: 0.1985 - val_accuracy: 0.9462\n","Epoch 67/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.2057 - accuracy: 0.9469 - val_loss: 0.1986 - val_accuracy: 0.9457\n","Epoch 68/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.2015 - accuracy: 0.9483\n","Epoch 68: 새로운 최상의 모델 발견 (val_loss: 0.1882)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.2031 - accuracy: 0.9473 - val_loss: 0.1882 - val_accuracy: 0.9511\n","Epoch 69/100\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1949 - accuracy: 0.9507 - val_loss: 0.1934 - val_accuracy: 0.9500\n","Epoch 70/100\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1976 - accuracy: 0.9477 - val_loss: 0.1903 - val_accuracy: 0.9478\n","Epoch 71/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1952 - accuracy: 0.9512\n","Epoch 71: 새로운 최상의 모델 발견 (val_loss: 0.1822)\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1922 - accuracy: 0.9530 - val_loss: 0.1822 - val_accuracy: 0.9511\n","Epoch 72/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1943 - accuracy: 0.9497\n","Epoch 72: 새로운 최상의 모델 발견 (val_loss: 0.1762)\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1912 - accuracy: 0.9508 - val_loss: 0.1762 - val_accuracy: 0.9543\n","Epoch 73/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1750 - accuracy: 0.9571\n","Epoch 73: 새로운 최상의 모델 발견 (val_loss: 0.1713)\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1763 - accuracy: 0.9562 - val_loss: 0.1713 - val_accuracy: 0.9559\n","Epoch 74/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1701 - accuracy: 0.9588\n","Epoch 74: 새로운 최상의 모델 발견 (val_loss: 0.1639)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1695 - accuracy: 0.9583 - val_loss: 0.1639 - val_accuracy: 0.9559\n","Epoch 75/100\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1715 - accuracy: 0.9589 - val_loss: 0.1726 - val_accuracy: 0.9522\n","Epoch 76/100\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1715 - accuracy: 0.9601 - val_loss: 0.1639 - val_accuracy: 0.9522\n","Epoch 77/100\n","8/8 [==============================] - 0s 41ms/step - loss: 0.1705 - accuracy: 0.9569 - val_loss: 0.1666 - val_accuracy: 0.9527\n","Epoch 78/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1600 - accuracy: 0.9611\n","Epoch 78: 새로운 최상의 모델 발견 (val_loss: 0.1564)\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1586 - accuracy: 0.9612 - val_loss: 0.1564 - val_accuracy: 0.9570\n","Epoch 79/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1522 - accuracy: 0.9644\n","Epoch 79: 새로운 최상의 모델 발견 (val_loss: 0.1557)\n","8/8 [==============================] - 0s 42ms/step - loss: 0.1537 - accuracy: 0.9644 - val_loss: 0.1557 - val_accuracy: 0.9586\n","Epoch 80/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1502 - accuracy: 0.9650\n","Epoch 80: 새로운 최상의 모델 발견 (val_loss: 0.1456)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1503 - accuracy: 0.9645 - val_loss: 0.1456 - val_accuracy: 0.9591\n","Epoch 81/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1457 - accuracy: 0.9669\n","Epoch 81: 새로운 최상의 모델 발견 (val_loss: 0.1396)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1469 - accuracy: 0.9671 - val_loss: 0.1396 - val_accuracy: 0.9640\n","Epoch 82/100\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1449 - accuracy: 0.9660 - val_loss: 0.1405 - val_accuracy: 0.9634\n","Epoch 83/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1389 - accuracy: 0.9666\n","Epoch 83: 새로운 최상의 모델 발견 (val_loss: 0.1339)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1387 - accuracy: 0.9659 - val_loss: 0.1339 - val_accuracy: 0.9645\n","Epoch 84/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1303 - accuracy: 0.9734\n","Epoch 84: 새로운 최상의 모델 발견 (val_loss: 0.1301)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1326 - accuracy: 0.9731 - val_loss: 0.1301 - val_accuracy: 0.9694\n","Epoch 85/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1312 - accuracy: 0.9721\n","Epoch 85: 새로운 최상의 모델 발견 (val_loss: 0.1236)\n","8/8 [==============================] - 0s 44ms/step - loss: 0.1287 - accuracy: 0.9728 - val_loss: 0.1236 - val_accuracy: 0.9704\n","Epoch 86/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1221 - accuracy: 0.9755\n","Epoch 86: 새로운 최상의 모델 발견 (val_loss: 0.1178)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1222 - accuracy: 0.9754 - val_loss: 0.1178 - val_accuracy: 0.9758\n","Epoch 87/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1171 - accuracy: 0.9770\n","Epoch 87: 새로운 최상의 모델 발견 (val_loss: 0.1156)\n","8/8 [==============================] - 0s 43ms/step - loss: 0.1210 - accuracy: 0.9754 - val_loss: 0.1156 - val_accuracy: 0.9720\n","Epoch 88/100\n","8/8 [==============================] - 0s 42ms/step - loss: 0.1162 - accuracy: 0.9780 - val_loss: 0.1163 - val_accuracy: 0.9742\n","Epoch 89/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1202 - accuracy: 0.9744\n","Epoch 89: 새로운 최상의 모델 발견 (val_loss: 0.1102)\n","8/8 [==============================] - 0s 42ms/step - loss: 0.1197 - accuracy: 0.9746 - val_loss: 0.1102 - val_accuracy: 0.9737\n","Epoch 90/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1207 - accuracy: 0.9728 - val_loss: 0.1123 - val_accuracy: 0.9720\n","Epoch 91/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1182 - accuracy: 0.9737 - val_loss: 0.1165 - val_accuracy: 0.9731\n","Epoch 92/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1172 - accuracy: 0.9758 - val_loss: 0.1130 - val_accuracy: 0.9694\n","Epoch 93/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1166 - accuracy: 0.9722 - val_loss: 0.1121 - val_accuracy: 0.9731\n","Epoch 94/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1089 - accuracy: 0.9780\n","Epoch 94: 새로운 최상의 모델 발견 (val_loss: 0.1005)\n","8/8 [==============================] - 0s 46ms/step - loss: 0.1101 - accuracy: 0.9769 - val_loss: 0.1005 - val_accuracy: 0.9769\n","Epoch 95/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.1037 - accuracy: 0.9796\n","Epoch 95: 새로운 최상의 모델 발견 (val_loss: 0.0971)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.1035 - accuracy: 0.9796 - val_loss: 0.0971 - val_accuracy: 0.9796\n","Epoch 96/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.0989 - accuracy: 0.9821 - val_loss: 0.0975 - val_accuracy: 0.9774\n","Epoch 97/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0970 - accuracy: 0.9793\n","Epoch 97: 새로운 최상의 모델 발견 (val_loss: 0.0931)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.0971 - accuracy: 0.9788 - val_loss: 0.0931 - val_accuracy: 0.9828\n","Epoch 98/100\n","8/8 [==============================] - 0s 45ms/step - loss: 0.0977 - accuracy: 0.9812 - val_loss: 0.1000 - val_accuracy: 0.9801\n","Epoch 99/100\n","7/8 [=========================>....] - ETA: 0s - loss: 0.0981 - accuracy: 0.9817\n","Epoch 99: 새로운 최상의 모델 발견 (val_loss: 0.0880)\n","8/8 [==============================] - 0s 45ms/step - loss: 0.0979 - accuracy: 0.9817 - val_loss: 0.0880 - val_accuracy: 0.9828\n","Epoch 100/100\n","8/8 [==============================] - 0s 44ms/step - loss: 0.0884 - accuracy: 0.9855 - val_loss: 0.0887 - val_accuracy: 0.9780\n","입력 각도: [16, -29, 22, 5, -18, 27, 20, -7]\n","생성된 피드백: \"오른쪽 팔꿈치와 오른쪽 무릎을 더 구부려주시고, 왼쪽 팔꿈치는 더 펴주세요.오른쪽 발목을 더 펴주시고 왼쪽 발목과 오른쪽 골반은 더 구부려주세요.\"\n","3/3 [==============================] - 0s 13ms/step - loss: 0.0739 - accuracy: 0.9902\n","Test Loss: 0.07394503057003021\n","Test Accuracy: 0.9902377128601074\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 4-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 3-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.10/dist-packages/nltk/translate/bleu_score.py:552: UserWarning: \n","The hypothesis contains 0 counts of 2-gram overlaps.\n","Therefore the BLEU score evaluates to 0, independently of\n","how many N-gram overlaps of lower order it contains.\n","Consider using lower n-gram order or use SmoothingFunction()\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["Average BLEU Score: 0.5140593383465454\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"8_tsjig5MhNR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dYtD2CgkOcK2"},"execution_count":null,"outputs":[]}]}