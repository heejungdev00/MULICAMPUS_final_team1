{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36224249-55f0-4ab2-b6d2-271d4690fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# 랜드마크 이름 리스트\n",
    "POSE_LANDMARKS = [\n",
    "    'NOSE', 'LEFT_EYE_INNER', 'LEFT_EYE', 'LEFT_EYE_OUTER', 'RIGHT_EYE_INNER', 'RIGHT_EYE', 'RIGHT_EYE_OUTER',\n",
    "    'LEFT_EAR', 'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT', 'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW',\n",
    "    'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX',\n",
    "    'LEFT_THUMB', 'RIGHT_THUMB', 'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE',\n",
    "    'LEFT_HEEL', 'RIGHT_HEEL', 'LEFT_FOOT_INDEX', 'RIGHT_FOOT_INDEX'\n",
    "]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"웹캠에서 프레임을 읽을 수 없습니다.\")\n",
    "            continue\n",
    "\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                results.pose_landmarks,\n",
    "                mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "            \n",
    "          \n",
    "            for idx, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "                h, w, c = image.shape\n",
    "                cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "                cv2.circle(image, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
    "                cv2.putText(image, f'{idx}: {POSE_LANDMARKS[idx]}', (cx + 10, cy),\n",
    "                            cv2.FONT_HERSHEY_PLAIN, 0.8, (0, 0, 255), 1)\n",
    "\n",
    "        cv2.imshow('MediaPipe Pose with Landmarks', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "237f37e9-caf1-46fb-a9e8-4002843b88f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'landmark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 55\u001b[0m\n\u001b[0;32m     46\u001b[0m mp_drawing\u001b[38;5;241m.\u001b[39mdraw_landmarks(\n\u001b[0;32m     47\u001b[0m         image,\n\u001b[0;32m     48\u001b[0m         results\u001b[38;5;241m.\u001b[39mpose_landmarks,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m         mp_drawing\u001b[38;5;241m.\u001b[39mDrawingSpec(color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m245\u001b[39m,\u001b[38;5;241m66\u001b[39m,\u001b[38;5;241m230\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, circle_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     52\u001b[0m     )\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# 선택된 랜드마크에 대해서만 라벨 표시\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, landmark \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results\u001b[38;5;241m.\u001b[39mpose_landmarks\u001b[38;5;241m.\u001b[39mlandmark):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m SELECTED_LANDMARK_INDICES:\n\u001b[0;32m     57\u001b[0m         h, w, c \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'landmark'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# 선택된 랜드마크 리스트\n",
    "SELECTED_LANDMARKS = [\n",
    "    'NOSE', 'LEFT_EYE_INNER', 'LEFT_EYE', 'LEFT_EYE_OUTER', 'RIGHT_EYE_INNER', 'RIGHT_EYE', 'RIGHT_EYE_OUTER',\n",
    "    'LEFT_EAR', 'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT', 'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW',\n",
    "    'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX',\n",
    "    'LEFT_THUMB', 'RIGHT_THUMB', 'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE',\n",
    "    'LEFT_HEEL', 'RIGHT_HEEL', 'LEFT_FOOT_INDEX', 'RIGHT_FOOT_INDEX'\n",
    "]\n",
    "\n",
    "#1~33까지 인덱스 중에서 위에서 고른 랜드마크의 고유 인덱스를 얻어서 S_L_I 변수에 저장\n",
    "SELECTED_LANDMARK_INDICES = [mp_pose.PoseLandmark[landmark].value for landmark in SELECTED_LANDMARKS]\n",
    "#비디오 캡쳐\n",
    "video_path=\"비디오 경로\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap_video=cv2.VideoCapture(video_path)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose: \n",
    "    #min_detection_confidence와 min_tracking_confidence는 각각 최소 감지 신뢰도와 최소 추적 신뢰도를 설정하고 Pose객체를 초기화\n",
    "    while cap.isOpened(): #웹캠의 cap이 열려있는동안 반복실행\n",
    "        success, image = cap.read() #cap의 프레임이 제대로 들어갔는지에 대한 불리언값과 그 프레임의 이미지를 저장\n",
    "        if not success: #프레임이 제대로 들어가지 않아 False가 저장되어있을경우 메세지를 출력 해주고 이어서 실행\n",
    "            print(\"웹캠에서 프레임을 읽을 수 없습니다.\")\n",
    "            continue\n",
    "\n",
    "        image.flags.writeable = False #이미지 파일을 불러올때 쓰기 권한을 False로 해제. 읽기권한만 있는 상태로 읽어들어오는것이 더 빠름.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) #mediapipe는 RGB 형식으로 이미지를 처리하고 cv는 BGR로 처리하기때문에 mediapipe에 맞게 변환\n",
    "        results = pose.process(image) #pose객체로 이미지를 처리해서 관절을 추적 이때 추적된 관절들의 정보가 results에 저장됨\n",
    "        image.flags.writeable = True #이미지의 쓰기권한을 부여\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) #pose처리가 된 이미지를 다시 cv 형식으로 바꿈\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            # 선택된 랜드마크만 그리기\n",
    "            landmarks_to_draw = mp_pose.PoseLandmark._member_names_\n",
    "            connections_to_draw = [\n",
    "                connection for connection in mp_pose.POSE_CONNECTIONS\n",
    "                if connection[0] in SELECTED_LANDMARK_INDICES and connection[1] in SELECTED_LANDMARK_INDICES\n",
    "            ]\n",
    "\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image,\n",
    "                results.pose_landmarks,\n",
    "                connections_to_draw,\n",
    "                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "\n",
    "            # 선택된 랜드마크에 대해서만 라벨 표시\n",
    "            for idx, landmark in enumerate(results.pose_landmarks.landmark):\n",
    "                if idx in SELECTED_LANDMARK_INDICES:\n",
    "                    h, w, c = image.shape\n",
    "                    cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "                    cv2.circle(image, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
    "                    cv2.putText(image, f'{SELECTED_LANDMARKS[SELECTED_LANDMARK_INDICES.index(idx)]}', \n",
    "                                (cx + 10, cy), cv2.FONT_HERSHEY_PLAIN, 0.8, (0, 0, 255), 1)\n",
    "\n",
    "        cv2.imshow('MediaPipe Pose with Selected Landmarks', image)\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "780ac8d6-0211-45e8-8f81-66a8b1e03a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11abb8df-9e4a-48a6-be71-9575ddbad875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_pose.PoseLandmark['LEFT_EYE_INNER'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "daaa29aa-c8f3-49f6-8964-1b369c4c4368",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 102\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m angles\n\u001b[0;32m    101\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 102\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    103\u001b[0m cap_video \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(video_path)\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mp_pose\u001b[38;5;241m.\u001b[39mPose(min_detection_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, min_tracking_confidence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pose:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "SELECTED_LANDMARKS = [\n",
    "    'NOSE', 'LEFT_EYE_INNER', 'LEFT_EYE', 'LEFT_EYE_OUTER', 'RIGHT_EYE_INNER', 'RIGHT_EYE', 'RIGHT_EYE_OUTER',\n",
    "    'LEFT_EAR', 'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT', 'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW',\n",
    "    'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX',\n",
    "    'LEFT_THUMB', 'RIGHT_THUMB', 'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE',\n",
    "    'LEFT_HEEL', 'RIGHT_HEEL', 'LEFT_FOOT_INDEX', 'RIGHT_FOOT_INDEX'\n",
    "]\n",
    "\n",
    "SELECTED_LANDMARK_INDICES = [mp_pose.PoseLandmark[landmark].value for landmark in SELECTED_LANDMARKS]\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "\n",
    "    return np.degrees(angle)\n",
    "#관절의 각도 계산 b관절을 기준으로 a관절과 c관절의 cos값을 계산. cos값이 -1~1까지 나오므로 코사인의 역함수 값을 취하면 0~180도가 나옴. cos(-1): 180 cos(0):90\n",
    "#cos (0도) = 1   cos(90도) =0 cos (180도) = -1\n",
    "\n",
    "\n",
    "def process_frame(frame, pose):\n",
    "    frame.flags.writeable = False\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(frame)\n",
    "    frame.flags.writeable = True\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        connections_to_draw = [\n",
    "            connection for connection in mp_pose.POSE_CONNECTIONS\n",
    "            if connection[0] in SELECTED_LANDMARK_INDICES and connection[1] in SELECTED_LANDMARK_INDICES\n",
    "        ]\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.pose_landmarks, connections_to_draw,\n",
    "            mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "        )\n",
    "\n",
    "    return frame, results\n",
    "#관절의 좌표값을 얻어서 angles리스트에 담아 cal angles함수로 보냄\n",
    "def get_angles(landmarks):\n",
    "    angles = []\n",
    "    \n",
    "    # 오른쪽 팔꿈치 각도\n",
    "    right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "    right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "    right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "    angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "    angles.append((\"Right Elbow\", angle))\n",
    "\n",
    "    # 왼쪽 팔꿈치 각도\n",
    "    left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "    left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "    left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "    angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "    angles.append((\"Left Elbow\", angle))\n",
    "\n",
    "    # 오른쪽 무릎 각도\n",
    "    right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "    right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "    right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "    angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "    angles.append((\"Right Knee\", angle))\n",
    "\n",
    "    # 왼쪽 무릎 각도\n",
    "    left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "    left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "    left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "    angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "    angles.append((\"Left Knee\", angle))\n",
    "\n",
    "    \n",
    "    return angles\n",
    "\n",
    "video_path = \"fit.mp4\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap_video = cv2.VideoCapture(video_path)\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened() and cap_video.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        ret_video, frame_video = cap_video.read()\n",
    "\n",
    "        if not ret or not ret_video:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "\n",
    "        frame, results = process_frame(frame, pose)\n",
    "        frame_video, results_video = process_frame(frame_video, pose)\n",
    "\n",
    "        if results.pose_landmarks and results_video.pose_landmarks:\n",
    "            angles_webcam = get_angles(results.pose_landmarks.landmark)\n",
    "            angles_video = get_angles(results_video.pose_landmarks.landmark)\n",
    "            \n",
    "            angle_differences = np.array(angles_webcam) - np.array(angles_video)\n",
    "            \n",
    "            # 각도 차이를 화면에 표시\n",
    "            cv2.putText(frame, f\"Angle Diff: {angle_differences}\", \n",
    "                        (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        # 두 영상을 나란히 표시\n",
    "        combined_frame = np.hstack((frame, frame_video))\n",
    "        cv2.imshow('Webcam and Video Comparison', combined_frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cap_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c94df0c0-81ac-4ebf-b16d-b32ea74715d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "SELECTED_LANDMARKS = [\n",
    "    'NOSE', 'LEFT_EYE_INNER', 'LEFT_EYE', 'LEFT_EYE_OUTER', 'RIGHT_EYE_INNER', 'RIGHT_EYE', 'RIGHT_EYE_OUTER',\n",
    "    'LEFT_EAR', 'RIGHT_EAR', 'MOUTH_LEFT', 'MOUTH_RIGHT', 'LEFT_SHOULDER', 'RIGHT_SHOULDER', 'LEFT_ELBOW',\n",
    "    'RIGHT_ELBOW', 'LEFT_WRIST', 'RIGHT_WRIST', 'LEFT_PINKY', 'RIGHT_PINKY', 'LEFT_INDEX', 'RIGHT_INDEX',\n",
    "    'LEFT_THUMB', 'RIGHT_THUMB', 'LEFT_HIP', 'RIGHT_HIP', 'LEFT_KNEE', 'RIGHT_KNEE', 'LEFT_ANKLE', 'RIGHT_ANKLE',\n",
    "    'LEFT_HEEL', 'RIGHT_HEEL', 'LEFT_FOOT_INDEX', 'RIGHT_FOOT_INDEX'\n",
    "]\n",
    "\n",
    "SELECTED_LANDMARK_INDICES = [mp_pose.PoseLandmark[landmark].value for landmark in SELECTED_LANDMARKS]\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    ba = a - b\n",
    "    bc = c - b\n",
    "    \n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    angle = np.arccos(cosine_angle)\n",
    "\n",
    "    return np.degrees(angle)\n",
    "#관절의 각도 계산 b관절을 기준으로 a관절과 c관절의 cos값을 계산. cos값이 -1~1까지 나오므로 코사인의 역함수 값을 취하면 0~180도가 나옴. cos(-1): 180 cos(0):90\n",
    "#cos (0도) = 1   cos(90도) =0 cos (180도) = -1\n",
    "\n",
    "\n",
    "def process_frame(frame, pose):\n",
    "    frame.flags.writeable = False\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(frame)\n",
    "    frame.flags.writeable = True\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.pose_landmarks:\n",
    "        landmarks = results.pose_landmarks.landmark\n",
    "        connections_to_draw = [\n",
    "            connection for connection in mp_pose.POSE_CONNECTIONS\n",
    "            if connection[0] in SELECTED_LANDMARK_INDICES and connection[1] in SELECTED_LANDMARK_INDICES\n",
    "        ]\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame, results.pose_landmarks, connections_to_draw,\n",
    "            mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "            mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "        )\n",
    "\n",
    "    return frame, results\n",
    "#관절의 좌표값을 얻어서 angles리스트에 담아 cal angles함수로 보냄\n",
    "def get_angles(landmarks):\n",
    "    angles = []\n",
    "    \n",
    "    # 오른쪽 팔꿈치 각도\n",
    "    right_shoulder = [landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,\n",
    "                      landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "    right_elbow = [landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "    right_wrist = [landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "    angle = calculate_angle(right_shoulder, right_elbow, right_wrist)\n",
    "    angles.append(angle)\n",
    "\n",
    "    # 왼쪽 팔꿈치 각도\n",
    "    left_shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "                     landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "    left_elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "    left_wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "    angle = calculate_angle(left_shoulder, left_elbow, left_wrist)\n",
    "    angles.append(angle)\n",
    "\n",
    "    # 오른쪽 무릎 각도\n",
    "    right_hip = [landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value].y]\n",
    "    right_knee = [landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value].y]\n",
    "    right_ankle = [landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].x,\n",
    "                   landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value].y]\n",
    "    angle = calculate_angle(right_hip, right_knee, right_ankle)\n",
    "    angles.append(angle)\n",
    "\n",
    "    # 왼쪽 무릎 각도\n",
    "    left_hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,\n",
    "                landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "    left_knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,\n",
    "                 landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "    left_ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,\n",
    "                  landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "    angle = calculate_angle(left_hip, left_knee, left_ankle)\n",
    "    angles.append(angle)\n",
    "\n",
    "    return angles\n",
    "\n",
    "# 메인 루프 부분\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened() and cap_video.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        ret_video, frame_video = cap_video.read()\n",
    "\n",
    "        if not ret or not ret_video:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "\n",
    "        frame, results = process_frame(frame, pose)\n",
    "        frame_video, results_video = process_frame(frame_video, pose)\n",
    "\n",
    "        if results.pose_landmarks and results_video.pose_landmarks:\n",
    "            angles_webcam = get_angles(results.pose_landmarks.landmark)\n",
    "            angles_video = get_angles(results_video.pose_landmarks.landmark)\n",
    "            \n",
    "            angle_differences = np.array(angles_webcam) - np.array(angles_video)\n",
    "            \n",
    "            # 각도 차이를 화면에 표시\n",
    "            joint_names = [\"Right Elbow\", \"Left Elbow\", \"Right Knee\", \"Left Knee\"]\n",
    "            for i, (name, diff) in enumerate(zip(joint_names, angle_differences)):\n",
    "                cv2.putText(frame, f\"{name}: {diff:.2f}\", \n",
    "                            (10, 30 + i*30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "            # 각도 차이 배열 출력\n",
    "            print(f\"Angle differences: {angle_differences}\")\n",
    "\n",
    "        # 이미지 크기 맞추기\n",
    "        height = min(frame.shape[0], frame_video.shape[0])\n",
    "        width = min(frame.shape[1], frame_video.shape[1])\n",
    "\n",
    "        frame_resized = cv2.resize(frame, (width, height))\n",
    "        frame_video_resized = cv2.resize(frame_video, (width, height))\n",
    "\n",
    "        # 두 영상을 나란히 표시\n",
    "        combined_frame = np.hstack((frame_resized, frame_video_resized))\n",
    "        cv2.imshow('Webcam and Video Comparison', combined_frame)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cap_video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed5fb2f1-70f9-479b-ae99-a09393a8e46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle differences: [  27.10811191  -81.69426626 -157.8726598  -143.59231235]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Angle differences: {angle_differences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e85b4-2b2e-451d-a9b3-a395760e7024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
